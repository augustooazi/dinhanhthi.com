<!DOCTYPE html><html domain=".com" lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="default-src 'self';object-src 'none';script-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com/;style-src 'self' https://fonts.googleapis.com/ https://use.fontawesome.com/ 'unsafe-inline';img-src 'self' data:;font-src 'self' https://fonts.gstatic.com/ https://use.fontawesome.com/" http-equiv="Content-Security-Policy"><link href="/favicon.svg" rel="icon" type="image/svg+xml"><meta content="#f9c412" name="theme-color"><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name="robots"><title>Principal Component Analysis (PCA)</title><meta content="Principal Component Analysis (PCA)" property="og:title"><meta content="What? # Sometimes we need to &amp;quot;compress&amp;quot; our data to speed up algorithms or to visualize data. One way is to use dimensionality..." name="description"><meta content="What? # Sometimes we need to &amp;quot;compress&amp;quot; our data to speed up algorithms or to visualize data. One way is to use dimensionality..." property="og:description"><meta content="summary_large_image" name="twitter:card"><meta content="@dinhanhthi" name="twitter:site"><meta content="@dinhanhthi" name="twitter:creator"><meta content="/img/cats/ml.svg" property="og:image"><link href="https://dinhanhthi.com/principal-component-analysis/" rel="canonical"><meta content="no-referrer-when-downgrade" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="üî• Anh-Thi DINH"><link href="/" rel="preconnect" crossorigin=""><script src="/js/min.js?hash=70bdd86fac" async="" defer=""></script><script csp-hash="sha256-ZO6+QmLYhAEQAnjl/xe643cTrnHA858+XwtOmaWwuN8=">if (/Mac OS X/.test(navigator.userAgent))
      document
        .documentElement
        .classList
        .add('apple')</script><style>@charset "UTF-8";@font-face{font-display:swap;font-family:"Poppins";font-style:normal;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-regular.eot);src:local("Poppins Regular"),local("Poppins-Regular"),url(/fonts/poppins/poppins-v15-latin-regular.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-regular.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-regular.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-regular.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-regular.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:"Poppins";font-style:italic;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-italic.eot);src:local("Poppins Italic"),local("Poppins-Italic"),url(/fonts/poppins/poppins-v15-latin-italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:normal;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600.eot);src:local("Poppins SemiBold"),local("Poppins-SemiBold"),url(/fonts/poppins/poppins-v15-latin-600.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:italic;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600italic.eot);src:local("Poppins SemiBold Italic"),local("Poppins-SemiBoldItalic"),url(/fonts/poppins/poppins-v15-latin-600italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Recoleta';src:url(/fonts/recoleta/Recoleta-Bold.woff2) format("woff2"),url(/fonts/recoleta/Recoleta-Bold.woff) format("woff"),url(/fonts/poppins/Recoleta-Bold.ttf) format("truetype");font-weight:700;font-style:bold}*{border:0;box-sizing:border-box}:root{font-size:16.5px}main img{content-visibility:auto}::-webkit-scrollbar{height:10px;width:10px}::-webkit-scrollbar-thumb{background:#3e466b;border-radius:6px}::-webkit-scrollbar-thumb:hover{background:#aaa;cursor:pointer}::-webkit-scrollbar-track{background:#363948}::-webkit-scrollbar-corner{background:#282a36}body,html{font-family:"Poppins",Arial,Helvetica,sans-serif;font-size:16.5px}html{-webkit-text-size-adjust:100%}@supports (font-variation-settings:normal){html{font-family:"Poppins" var alt,Arial,Helvetica,sans-serif}}body{background:#282a36;color:#eee;margin:0;counter-reset:h2counter}b,strong{font-weight:600;color:#8cc8ff}sup{top:-.5em}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}a,a:hover{text-decoration:none}a:hover{border-bottom:2px solid #ffd479;color:#fff}a.no-effect:hover{border-bottom:none}img{max-width:100%}main{margin:0 auto}.page-note h3,.page-note>h2,h1,h2,h3{font-family:"Recoleta",Arial,Helvetica,sans-serif}h1{font-size:29.7px}h2{font-size:24.75px}h3{font-size:21.5325px}.page-note h3,.page-note>h2{color:#eee}.page-note h3:hover .direct-link,.page-note>h2:hover .direct-link{display:inline-block}.page-note h3:hover a:hover,.page-note>h2:hover a:hover,a{color:#ffd479}.page-note>h2{font-size:24.75px;margin:37.125px 0 19.8px}.page-note p+ol,.page-note p+ul,.page-note>h2+h3{margin-top:-.5rem}.page-note>h3{font-size:21.5325px;margin-bottom:19.8px}.page-note .direct-link{display:none;color:#777;border-bottom:none;margin-left:3px}.page-note pre+h2,.page-note pre+h3,.page-note>h3{margin-top:37.125px}.page-note h1{counter-reset:h2counter}.page-note h2{counter-reset:h3counter}.page-note h3{counter-reset:h4counter}.page-note h3:before{opacity:.5;content:counter(h2counter) "." counter(h3counter) ".¬†¬†";counter-increment:h3counter}.page-note h2:before{content:counter(h2counter) ".¬†¬†";counter-increment:h2counter;color:#8cc8ff}.container,header{width:100%;margin:0 auto}.normal{padding:0 16.5px;width:100%}@media (min-width:916.5px){.normal{width:900px}}.mt-2{margin-top:2rem}.page-index .container{padding:2rem 1rem 0}.page-index .main-cats{flex:0 1 calc(100% - 280px);padding-right:1rem}.page-index .main-cats>.category-wrapper{padding-bottom:1.5rem}.page-index .main-cats>.category-wrapper>.category{border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:2rem 1.5rem 1.5rem}.page-index .toc-index{border:1px solid #404040;border-radius:7px;height:fit-content;background:#35373c;flex:0 1 280px;position:sticky;top:60px;padding:1rem 1.1rem}.page-index .toc-index h3{padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 10px;font-size:1.3rem}.page-index .toc-index ul{padding-left:20px;margin:0}.page-index .toc-index p{font-style:italic;color:#999;padding-top:0;margin-bottom:0;font-size:.95rem;margin-top:10px}.page-index .toc-index p a{color:#999;border-bottom:2px solid #999}.page-index .toc-index p a:hover{border-bottom:2px solid #ffd479}@media (max-width:991px){.page-index .main-cats{flex:1 1 100%;order:2;padding-right:0}.page-index .toc-index{flex:1 1 100%;order:1;position:inherit;margin-bottom:1.5rem}.page-index .toc-index ul{column-count:3;-webkit-column-count:3;-moz-column-count:3}}@media (max-width:767px){.page-index .toc-index ul{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (max-width:575px){.page-index .toc-index ul{column-count:1;-webkit-column-count:1;-moz-column-count:1}}.category{width:100%}.category h2,header h1{font-size:1.55rem;margin-top:0}.category h2 img{float:left;margin-right:7px}.category .list-homepage{list-style:none;padding-left:10px;margin-bottom:0;column-count:1;-webkit-column-count:1;-moz-column-count:1}@media (min-width:768px){.category .list-homepage{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (min-width:992px){.category .list-homepage{column-count:3;-webkit-column-count:3;-moz-column-count:3}}.category .list-homepage li{padding-left:15px;margin-bottom:10px;display:inline-block;width:100%}.category .list-homepage li a{color:#ddd;border-bottom:2px solid rgba(255,255,255,.14);border-style:dotted}.category .list-homepage li::before{content:"üìÑ";margin-right:5px;margin-left:-25px;opacity:.8}.category .list-homepage li:hover{cursor:pointer}.category .list-homepage li:hover a{border-color:#ffd479;color:#fff}.category .list-homepage li:hover::before{opacity:1}.page-index header{padding-top:5em;padding-bottom:0}.page-index header .header-logo{height:80px;width:auto}header nav{z-index:10}#nav{z-index:2;position:relative}header{padding:5.5rem 1.5rem 1rem;width:900px;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header h1{font-size:2.2rem;margin-bottom:0}header p{margin-top:1rem}header .header-logo{width:55px;height:55px;margin-bottom:1rem}header .header-logo img{width:100%;height:100%}header .social{margin-top:.5rem}header #more-info #note-tag>a,header .social a{margin-right:10px}header .social a:last-child{margin-right:0}@media (min-width:992px){header .social a{margin-right:20px}}header .social a img{border-radius:50%}header #more-info{padding:1rem}header #more-info #note-tag{padding-bottom:10px;border-bottom:1px solid #444}header #more-info #note-tag>a::before{content:"#"}header #more-info #last-modified{padding-top:10px;font-style:italic}#reading-progress,nav{top:0;left:0;width:100vw}#reading-progress{z-index:3;border-bottom:1px solid #ffd479;position:absolute;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}.intro,.job span{font-size:1.02rem}.intro b,.intro strong{color:#ffd479;font-weight:400}.intro a,footer a:hover{color:#fff}.job span{background:#ffd479;color:#000;padding:3px 10px;border-radius:15px}nav{position:fixed;padding:0 1.5em;background:#35373c}@media (max-width:992px){nav{padding:0 1em}}@media (max-width:576px){nav{padding:0 .5em}}nav #nav{display:-ms-flexbox;-ms-flex-align:center;align-items:center}nav #nav a{color:#ccc;margin-right:15px;align-items:center;padding:0 .5rem;font-size:1.1rem;white-space:nowrap}nav #nav a img{margin-right:5px}nav #nav a:hover{color:#fff;cursor:pointer;text-decoration:none}nav #nav .nav-item{text-align:left;margin-right:5px}@media (min-width:421px){nav #nav .nav-item{padding-left:0!important}}@media (max-width:575px){nav #nav .nav-item{width:unset!important}nav #nav .nav-item span{display:none}}@media (min-width:576px){nav #nav .nav-item{margin-right:15px}}nav #nav .nav-github{text-align:right;padding-right:0!important;margin-right:0!important}nav #nav .nav-search{display:block;background-image:linear-gradient(to right,#3d4251,#3b3f4c,#393d46,#373a41,#35373c);width:100%;position:relative}nav #nav,nav #nav .nav-search form,nav #nav a{display:flex}nav #nav .nav-search .nav-search-input{border:0;background:0 0;color:#ddd;font-size:1.05rem;padding:.65rem .5rem;width:100%}nav #nav .nav-search .nav-search-input:focus{outline:0;border:0}nav #nav .nav-search #search-result{position:absolute;max-height:80vh;overflow:auto;width:100%;background:#35373c;border-bottom-right-radius:5px;border-bottom-left-radius:5px;padding:0 1rem}@media (max-width:767px){nav #nav .nav-search #search-result{position:fixed;left:0;right:0;border-radius:0}}nav #nav .nav-search #search-result ul#searchResults{padding:0 0 0 20px}.page-note ol li,.page-note ul li,div.toc ol li,nav #nav .nav-search #search-result ul#searchResults li h3{margin-bottom:5px}nav #nav .nav-search #search-result ul#searchResults li h3 a{color:#efb232;white-space:inherit;padding:0;text-align:left;font-weight:400;font-size:16.5px;font-family:"Poppins",Arial,Helvetica,sans-serif;line-height:1.4}nav #nav .nav-search #search-result ul#searchResults li h3 a:hover{border-bottom:none;color:#8cc8ff}nav #nav .nav-search #search-result ul#searchResults li p{text-align:left;margin-top:0;line-height:1.4}nav #nav .nav-search #search-result #noResultsFound p{text-align:left}footer{font-size:1.1rem;background:#35373c;padding:.75rem 1rem;text-align:center;margin-top:3rem}footer a{color:#ccc}.warning{position:relative;padding:16.5px;margin-bottom:24.75px;border:1px solid transparent;border-radius:.25rem;color:#eee;border-left-width:15px;border-color:#ffd479}.warning :last-child{margin-bottom:0}.hsbox{margin-bottom:24.75px;border:1px solid #969696;padding:1rem;border-radius:3px}.hsbox .hs__title{cursor:pointer}.hsbox .hs__title::before{content:" ";display:inline-block;border-top:7px solid transparent;border-bottom:7px solid transparent;border-left:7px solid currentColor;vertical-align:middle;margin-right:.7rem;transform:translateY(-2px);transition:transform .2s ease-out}.hsbox .hs__title.show{padding-bottom:15px;border-bottom:.5px solid #666;margin-bottom:1rem}.hsbox .hs__title.show+.hs__content{display:block;opacity:1;padding:5px 0;transition:all .25s 0s cubic-bezier(.4,0,.2,1)}.hsbox .hs__title.show::before{transform:rotate(90deg) translateX(-3px)}.hsbox .hs__content{display:none;transition:all .2s 0s ease}.hsbox .hs__content>:last-child{margin-bottom:0}.katex{font:1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;text-indent:0;text-rendering:auto}.katex *{-ms-high-contrast-adjust:none!important}.katex .katex-mathml{position:absolute;clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}.katex .base{position:relative;white-space:nowrap;width:min-content}.katex .base,.katex .strut,.katex .vlist>span>span{display:inline-block}.katex .vlist-t{display:inline-table;table-layout:fixed}.katex .vlist-r{display:table-row}.katex .vlist{display:table-cell;vertical-align:bottom;position:relative}.katex .vlist>span{height:0}.katex .vlist>span>.pstrut{overflow:hidden;width:0}.katex .vlist-t2{margin-right:-2px}.katex .vlist-s{display:table-cell;vertical-align:bottom;font-size:1px;width:2px;min-width:2px}.katex .msupsub{text-align:left}.katex .mspace{display:inline-block}.katex .sizing.reset-size6.size3{font-size:.7em}.katex svg{display:block;position:absolute;width:100%;height:inherit;fill:currentColor;stroke:currentColor;fill-rule:nonzero;fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1}.katex img{border-style:none;min-width:0;min-height:0;max-width:none;max-height:none}.katex-display{display:block;margin:1em 0}.katex-display>.katex{display:block;text-align:center;white-space:nowrap}.katex .vlist>span,.katex-display>.katex>.katex-html{display:block;position:relative}.katex-display,.page-note .text-center{text-align:center}.page-note ol,.page-note p,.page-note ul{margin-top:0;margin-bottom:24.75px}.page-note ol li ol,.page-note ol li ul,.page-note ul li ol,.page-note ul li ul{margin-bottom:5px;padding-left:20px}.page-note ol li>*,.page-note ul li>*{margin-bottom:10px}.page-note p.noindent{display:none;padding-left:20px}.page-note p.noindent+ol,.page-note p.noindent+ul{padding-left:20px}.page-note p.indent{display:none;padding-left:40px}.page-note ol.indent,.page-note p.indent+ol,.page-note p.indent+ul,.page-note ul.indent{padding-left:40px}.page-note ol.noindent,.page-note ul.noindent{padding-left:20px}.page-note hr{border-bottom:1px solid #676767;margin-bottom:24.75px}#reading-list .item .author{font-style:italic}#reading-list .item .intro{color:#999}code[class*=language-],pre[class*=language-]{color:#eee;font-size:16px;text-shadow:none;font-family:Menlo,Monaco,Consolas,"Andale Mono","Ubuntu Mono","Courier New",monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#75a7ca}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}.token.comment{color:#6a9955}.token.punctuation{color:#eee}.token.inserted,.token.number,.token.unit{color:#b5cea8}.token.operator{color:#eee}.token.boolean,.token.keyword{color:#90cdff}.token.property{color:#9cdcfe}pre[class*=language-]>code[class*=language-]{position:relative;z-index:1}code,pre{font-family:Consolas,Menlo,Monaco,"Andale Mono WT","Andale Mono","Lucida Console","Lucida Sans Typewriter","DejaVu Sans Mono","Bitstream Vera Sans Mono","Liberation Mono","Nimbus Mono L","Courier New",Courier,monospace;line-height:1.5}h2>code{font-size:21.78px!important}h3>code{font-size:18.9486px!important}:not(pre)>code{border:1px solid #444;background:#6b444245;padding:2px 4px;margin:0 1px;border-radius:3px;font-size:.9rem;color:#fff;word-break:break-word}h2>code,h3>code{color:#ddd;padding-right:6px}a>code{color:#ffd479}a:hover>code{color:#ccc}pre,pre[class*=language-]{margin:0 0 27.225px;overflow:auto}pre>code,pre[class*=language-]>code{display:block;padding:14.5px 16.5px 16.5px;background:#2f3240;border:.5px solid #3b3e54;overflow:auto;border-radius:3px;max-height:450px}div.toc{margin-bottom:24.75px;border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:15px 15px 10px 0}div.toc>ol::before{content:"In this note";display:block;padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 15px;font-size:1.18rem;font-family:"Recoleta",Arial,Helvetica,sans-serif}div.toc ol{padding-left:20px;font-size:14.85px;margin-bottom:0}div.toc ol li code{font-size:.85rem;background:#ececec;padding:0 4px 2px}div.toc ol li ol{padding-left:10px;margin-top:7px}div.toc ol,div.toc ol ol{counter-reset:item;list-style-type:none}div.toc ol li::before{content:counters(item,".") ". ";counter-increment:item}div.toc>ol>li ol>li::before{opacity:.7}div.toc>ol>li::before{color:#8cc8ff}@media (min-width:1300px){div.toc{float:right;margin-right:-280px;border-left:none;width:250px;position:-webkit-sticky;position:sticky;top:60px;max-height:70vh;overflow:auto}div.toc ol{margin-top:0;margin-bottom:0}}@media (min-width:1500px){div.toc{margin-right:-310px;width:280px}}.toc-active>a{color:#fff!important}.toc-active::before{opacity:1!important}.page-note img{height:auto;width:100%}@media (min-width:768px){.page-note .img-full-75{width:75%;margin-left:auto;margin-right:auto;display:block}.page-note .img-full-100,.page-note .img-full-90{width:90%;margin-left:auto;margin-right:auto;display:block}.page-note .img-full-100{width:100%}}.page-note p>img+br,.page-note p>picture+br{display:none}.page-note p>img+br+em,.page-note p>picture+br+em{display:block;text-align:center;margin-top:10px}</style></head><body><header><nav><div id="nav"><a href="/" class="nav-item no-effect"><img alt="home" height="18" src="/img/nav/home.svg" width="18"> <span>Thi</span> </a><a href="/about/" class="nav-item no-effect"><img alt="about" height="15" src="/img/nav/about.svg" width="15"> <span>About</span></a><div class="nav-search"><form><input aria-label="search notes..." class="nav-search-input" id="searchField" placeholder="search notes..." type="search"></form><div id="search-result" style="display: none;"><ul id="searchResults"></ul><div id="noResultsFound" style="display: none;"><p>No results found.</p></div></div></div><a href="https://github.com/dinhanhthi" class="nav-item no-effect nav-github" target="_blank"><img alt="github" height="20" src="/img/nav/github.svg" width="20"></a></div><div id="reading-progress" aria-hidden="true"></div></nav><div class="header-logo"><img alt="Principal Component Analysis (PCA)" height="512" src="/img/cats/ml.svg" width="512"></div><h1>Principal Component Analysis (PCA)</h1><div id="more-info"><div id="note-tag"><a href="/tags/machine-learning">Machine Learning</a></div><div id="last-modified">03-12-2020 / <a href="https://github.com/dinhanhthi/dinhanhthi.com/edit/dev/./posts/ml/2019-10-14-principal-component-analysis.md">Edit on Github</a></div></div></header><main><article><div class="container mt-2 normal page-note"><div class="toc"><ol><li><a href="#what%3F">What?</a><ol><li><a href="#algorithm">Algorithm</a></li></ol></li><li><a href="#code">Code</a><ol><li><a href="#whitening">Whitening</a></li></ol></li><li><a href="#pca-in-action">PCA in action</a></li><li><a href="#references">References</a></li></ol></div><h2 id="what%3F">What? <a href="#what%3F" class="direct-link">#</a></h2><p>Sometimes we need to "compress" our data to speed up algorithms or to visualize data. One way is to use <strong>dimensionality reduction</strong> which is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. We can think of 2 approaches:</p><ul><li><strong>Feature selection</strong>: find a subset of the input variables.</li><li><strong>Feature projection</strong> (also <em>Feature extraction</em>): transforms the data in the high-dimensional space to a space of fewer dimensions. <strong>PCA</strong> is one of the methods following this approach.</li></ul><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-1-1920w.webp 1920w, /img/post/ML/PCA/pca-1-1280w.webp 1280w, /img/post/ML/PCA/pca-1-640w.webp 640w, /img/post/ML/PCA/pca-1-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-1-1920w.jpg 1920w, /img/post/ML/PCA/pca-1-1280w.jpg 1280w, /img/post/ML/PCA/pca-1-640w.jpg 640w, /img/post/ML/PCA/pca-1-320w.jpg 320w" type="image/jpeg"><img alt="An idea of using PCA from 2D to 1D." height="750" src="/img/post/ML/PCA/pca-1.jpg" width="1721" class="pop img-full-90" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1721px) min(calc(var(--main-width) * 0.4357931435212086), 750px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1721 750'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAFCAIAAAD+GJp4AAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAeElEQVQI121Ouw7CMAzMd/Ml/E8lBr6AgY4dEEMhbZLzMziqmOBk+U5n6+xkZv0LNYnqP0iqOsYqte3gyvJviZhBNeeVCYfFXAiZsAF7aFEkIrRWxNxHXpDHRXfrw4gW5Kn7+EnmK5ZbiOd7OU+ntTxqs8v9dWR/APnlrvRlyko/AAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em><strong>Figure 1.</strong> An idea of using PCA from 2D to 1D.</em></p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-2-1920w.webp 1920w, /img/post/ML/PCA/pca-2-1280w.webp 1280w, /img/post/ML/PCA/pca-2-640w.webp 640w, /img/post/ML/PCA/pca-2-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-2-1920w.jpg 1920w, /img/post/ML/PCA/pca-2-1280w.jpg 1280w, /img/post/ML/PCA/pca-2-640w.jpg 640w, /img/post/ML/PCA/pca-2-320w.jpg 320w" type="image/jpeg"><img alt="An idea of using PCA from 5D to 2D." height="857" src="/img/post/ML/PCA/pca-2.jpg" width="1631" class="pop img-full-75" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1631px) min(calc(var(--main-width) * 0.5254445125689761), 857px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1631 857'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAGCAIAAACaUPOvAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAq0lEQVQI1y1O7QqCQBC8l+9Feo4gJTIvEgKjwAr9YZl2Fumd533ttUazCzPsDswQjwBgfT2awf8B1plpwQA4IlR3KPfLY5AUsbIC/6OWSU7TkkbnqOUPMmqRFHSdhZfmpKxEx6CGbR5ursEqWzRdSfAklXjzl4ffeO/AtqKqP3fGS6k5AYwC8EYZNToHTFSD5pPPeeumUgRrIuliZzuGYk5n6S1GkT/7op1Cv7zjuT1TQ21NAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em><strong>Figure 2.</strong> An idea of using PCA from 5D to 2D.</em></p><div class="warning"><p>‚ùì <strong class="tbrown">Questions</strong>: How can we choose the <strong class="tgreen">green arrows</strong> like in Figure 1 and 2 (their <strong>directions</strong> and their <strong>magnitudes</strong>)?</p></div><p>From a data points, there are many ways of projections, for examples,</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-4-1920w.webp 1920w, /img/post/ML/PCA/pca-4-1280w.webp 1280w, /img/post/ML/PCA/pca-4-640w.webp 640w, /img/post/ML/PCA/pca-4-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-4-1920w.jpg 1920w, /img/post/ML/PCA/pca-4-1280w.jpg 1280w, /img/post/ML/PCA/pca-4-640w.jpg 640w, /img/post/ML/PCA/pca-4-320w.jpg 320w" type="image/jpeg"><img alt="An example of different projections." height="553" src="/img/post/ML/PCA/pca-4.jpg" width="1383" class="pop img-full-75" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1383px) min(calc(var(--main-width) * 0.39985538684020244), 553px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1383 553'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAFCAIAAAD+GJp4AAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAbElEQVQI13WOwQ7DMAhD8/9/Omlqt1YhiTFOSW47zPIBpGdwmVshDcT8oyLJqas6KXeTNir9QPS4jMnBDsKEGecR9z2Gm1nEyhS8Xxn2dtJ7nkH/oqU/gLXWaq0ky+rSEYH9JJO+TF/z3rPPAxLosNddffGFAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em><strong>Figure 3.</strong> We will project the points to the green line or the violet line? Which one is the best choice?</em></p><p>Intuitively, the green line is better with more separated points. But how can we choose it "mathematically" (precisely)? We need to know about:</p><ul><li><strong><a href="/mean-median-mode">Mean</a></strong>: find the most balanced point in the data.</li><li><strong><a href="/variance-covariance-correlation">Variance</a></strong>: measure the spread of data from the mean. However, variance is not enough. There are many different ways in that we get the same variance.</li><li><strong><a href="/variance-covariance-correlation">Covariance</a></strong>: indicate the direction in that data are spreading.</li></ul><p>An example of the same mean and variance but different covariance.</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-5-1920w.webp 1920w, /img/post/ML/PCA/pca-5-1280w.webp 1280w, /img/post/ML/PCA/pca-5-640w.webp 640w, /img/post/ML/PCA/pca-5-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-5-1920w.jpg 1920w, /img/post/ML/PCA/pca-5-1280w.jpg 1280w, /img/post/ML/PCA/pca-5-640w.jpg 640w, /img/post/ML/PCA/pca-5-320w.jpg 320w" type="image/jpeg"><img alt="Different data but the same mean and variance." height="878" src="/img/post/ML/PCA/pca-5.jpg" width="1731" class="pop img-full-100" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1731px) min(calc(var(--main-width) * 0.5072212593876372), 878px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1731 878'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAGCAIAAACaUPOvAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAdElEQVQI102NUQ7DMAhDc/+bdlE7IJARYNmIpkbzFxbPdun9NcaIiDnn55aZcSN3z7vkj0WQKLn0yfUuLa2q+4qVX9r/OtwswndjYWZVNfM9obcytggAqLVe0DYhItd5Po6Duy4CEak1IM7R3UFEjM+3W9ovLB3BCZJe89EAAAAASUVORK5CYII='%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em><strong>Figure 4.</strong> Different data but the same mean and variance. That's why we need covariance!</em></p><h3 id="algorithm">Algorithm <a href="#algorithm" class="direct-link">#</a></h3><ol><li><p>Subtract the mean to move to the original axes.</p></li><li><p>From the original data (a lot of features <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">x_1, x_2, \ldots, x_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">‚Ä¶</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>), we construct a <strong>covariance matrix <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span></strong>.</p></li><li><p>Find the <strong class="tbrown">eigenvalues</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Œª</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo></mrow><annotation encoding="application/x-tex">\lambda_1, \lambda_2,\ldots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Œª</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">Œª</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">‚Ä¶</span></span></span></span> and correspondent <strong>eigenvectors</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo></mrow><annotation encoding="application/x-tex">v_1, v_2, \ldots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">‚Ä¶</span></span></span></span> of that matrix (we call them <strong>eigenstuffs</strong>). Choose <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>&lt;</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">K &lt; N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> couples <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">Œª</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> (the highest eigenvalues) and we get a reduced matrix <em><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">U_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></em>.</p></li><li><p>Projection original data points to the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>-dimensional plane created based on these new <em>eigenstuffs</em>. This step creates new data points on a new dimensional space (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>).</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Z</mi><mo>=</mo><msubsup><mi>U</mi><mi>K</mi><mi>T</mi></msubsup><mi>X</mi></mrow><annotation encoding="application/x-tex">Z = U_K^TX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.138331em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="mtight reset-size6 size3 sizing"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></span></p></li><li><p>Now, instead of solving the original problem (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> features), we only need to solve a new problem with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> features (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>&lt;</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">K&lt;N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>).</p></li></ol><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-3-1920w.webp 1920w, /img/post/ML/PCA/pca-3-1280w.webp 1280w, /img/post/ML/PCA/pca-3-640w.webp 640w, /img/post/ML/PCA/pca-3-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-3-1920w.jpg 1920w, /img/post/ML/PCA/pca-3-1280w.jpg 1280w, /img/post/ML/PCA/pca-3-640w.jpg 640w, /img/post/ML/PCA/pca-3-320w.jpg 320w" type="image/jpeg"><img alt="A big picture of the idea of PCA algorithm." height="1053" src="/img/post/ML/PCA/pca-3.jpg" width="1906" class="pop img-full-100" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1906px) min(calc(var(--main-width) * 0.5524658971668416), 1053px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1906 1053'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAIAAAB1kpiRAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAApUlEQVQI1yXO0WrDMAxAUf//X41CYTBoobBB1yRjG0sbJ07SSJZtWdIKfbkv5+W6l4NfoYgopspVzezZgEPjT+7w4e/zFCFsmCMsQuvUfhrnjdZv37hzNwGgcFK1msFS4DCacEw4zL07tyPGwpq/fIcUlAEKlZpj2q7hz71fxkj1TvNb+7rAgPCzb3bd7UjQ9w/ufpdI5fGiIqamKomjCFPGcb39A5/zqYluQQYZAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em><strong>Figure 5.</strong> A big picture of the idea of PCA algorithm.<sup><a href="https://www.youtube.com/watch?v=g-Hb26agBFg">[ref]</a></sup></em></p><h2 id="code">Code <a href="#code" class="direct-link">#</a></h2><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA<br><br>s <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">,</span> whiten<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><br><span class="token comment"># pca.fit(s)</span><br>s1 <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>s<span class="token punctuation">)</span><br><br><span class="token keyword">print</span> <span class="token punctuation">(</span>pca<span class="token punctuation">.</span>components_<span class="token punctuation">)</span> <span class="token comment"># eigenvectors</span><br><span class="token keyword">print</span> <span class="token punctuation">(</span>pca<span class="token punctuation">.</span>explained_variance_<span class="token punctuation">)</span> <span class="token comment"># eigenvalues</span></code></pre><p>Some notable components (see <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">full</a>):</p><ul><li><code class="tpink">pca.fit(X)</code>: only fit <code>X</code> (and then we can use <code>pca</code> for other operations).</li><li><code class="tpink">pca.fit_transform(X)</code>: Fit the model with <code>X</code> and apply the dimensionality reduction on <code>X</code> (from <code>(n_samples, n_features)</code> to <code>(n_samples, n_components)</code>).</li><li><code class="tpink">pca.inverse_transform(s1)</code>: transform <code>s1</code> back to original data space (2D) - not back to <code>s</code>!!!</li><li><code class="tpink">pca1.mean_</code>: mean point of the data.</li><li><code class="tpink">pca.components_</code>: eigenvectors (<code>n_components</code> vectors).</li><li><code class="tpink">pca.explained_variance_</code>: eigenvalues. It's also the amount of retained variance which is corresponding to <strong>each</strong> components.</li><li><code class="tpink">pca.explained_variance_ratio_</code>: the <strong>percentage</strong> in that variance is retained if we consider on <strong>each</strong> component.</li></ul><p>Some notable parameters:</p><ul><li><code class="tpink">n_components=0.80</code>: means it will return the Eigenvectors that have the 80% of the variation in the dataset.</li></ul><div class="warning"><p>When choosing the number of principal components (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>), we choose <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> to be the smallest value so that for example, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>99</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">99\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">9</span><span class="mord">9</span><span class="mord">%</span></span></span></span> of variance, is retained.<sup><a href="https://stackoverflow.com/questions/32857029/python-scikit-learn-pca-explained-variance-ratio-cutoff" target="_blank" rel="noopener noreferrer">[ref]</a></sup></p><p>In <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">Scikit-learn</a>, we can use <code>pca.explained_variance_ratio_.cumsum()</code>. For example, <code>n_components = 5</code> and we have,</p><pre class="language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token number">0.32047581</span>  <span class="token number">0.59549787</span>  <span class="token number">0.80178824</span>  <span class="token number">0.932976</span>    <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span></code></pre><p>then we know that with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">K=4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>, we would retain <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>93.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">93.3\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">9</span><span class="mord">3</span><span class="mord">.</span><span class="mord">3</span><span class="mord">%</span></span></span></span> of the variance.</p></div><h3 id="whitening">Whitening <a href="#whitening" class="direct-link">#</a></h3><p>Whitening makes the features:</p><ul><li>less correlated with each other,</li><li>all features have the same variance (or, unit component-wise variances).</li></ul><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-6-1920w.webp 1920w, /img/post/ML/PCA/pca-6-1280w.webp 1280w, /img/post/ML/PCA/pca-6-640w.webp 640w, /img/post/ML/PCA/pca-6-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/post/ML/PCA/pca-6-1920w.jpg 1920w, /img/post/ML/PCA/pca-6-1280w.jpg 1280w, /img/post/ML/PCA/pca-6-640w.jpg 640w, /img/post/ML/PCA/pca-6-320w.jpg 320w" type="image/jpeg"><img alt="An illustration of whitening." height="355" src="/img/post/ML/PCA/pca-6.jpeg" width="1037" class="pop img-full-100" decoding="async" loading="lazy" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1037px) min(calc(var(--main-width) * 0.3423336547733848), 355px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1037 355'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA0AAAAFCAIAAAAR2vFGAAAACXBIWXMAAAPoAAAD6AG1e1JrAAAAq0lEQVQI1zWO0QqCUAyGz8P7BF77BkXd9QJChRAZ3khJEqWGqamox+14zppCPwz2bx//Jro8/8axbBqtDSK+q+T1eaTFU4LUeqpKFUWQJCiICAG6ukGlmKO/uAcAIkOk2c7ccbMN94eJSA7SDy/OynFP7rCIOctan/27UAA72x77nvMAxrIug2uQ5um4iFM871YUrejbtsgybYyUcl4YMpqL+ChPEJUxmh/9AdWFtWPn8iNqAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)"></picture><br><em>PCA / Whitening. <strong>Left</strong>: Original toy, 2-dimensional input data. <strong>Middle</strong>: After performing PCA. The data is centered at zero and then rotated into the eigenbasis of the data covariance matrix. This decorrelates the data (the covariance matrix becomes diagonal). <strong>Right</strong>: Each dimension is additionally scaled by the eigenvalues, transforming the data covariance matrix into the identity matrix. Geometrically, this corresponds to stretching and squeezing the data into an isotropic gaussian blob.</em></p><p>If this section doesn't satisfy you, read <a href="http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/#whitening">this</a> and <a href="http://cs231n.github.io/neural-networks-2/">this</a> (section <em>PCA and Whitening</em>).</p><h2 id="pca-in-action">PCA in action <a href="#pca-in-action" class="direct-link">#</a></h2><ul><li><p><strong>Example to understand the idea of PCA</strong>: <a href="/files/ml/pca/PCA_understanding_example.html">html file</a> -- <a href="https://colab.research.google.com/drive/1F_A_fJOY-oiV7Ly4y_evF9sfwII-ljJK">open in colab</a>.</p><ul><li>Plot points with 2 lines which are corresponding to 2 eigenvectors.</li><li>Plot &amp; choose Principal Components.</li><li>An example of choosing <code>n_components</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>.</li><li>Visualization hand-written digits (the case of all digits and the case of only 2 digits -- 1 &amp; 8).</li><li>Using <a href="/support-vector-machine">SVM</a> to classifier data in the case of 1 &amp; 8 and visualize the decision boundaries.</li></ul></li><li><p><strong>Image compression</strong>: <a href="/files/ml/pca/PCA-image-compression.html">html file</a> -- <a href="https://colab.research.google.com/drive/1G_WPZMmQ020kjSmqMI_k21_zLDrPlYtg">open in colab</a>.</p><ul><li>When input is an image, the values of adjacent pixels are <em>highly correlated</em>.</li><li>Import images from <code>scipy</code> and Google Drive or Github (with <code>git</code>).</li><li>Compress grayscale images and colored ones.</li><li>Plot a grayscale version of a colorful images.</li><li>Save output to file (Google Drive).</li><li>Fix warning <em>Lossy conversion from float64 to uint8. Range [...,...]. Convert image to uint8 prior to saving to suppress this warning.</em></li><li>Fix warning <em>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)</em>.</li><li>Calculate a size (in <code>KB</code>) of a image file.</li></ul></li><li><p><strong>PCA without scikit-learn</strong>: <a href="/files/ml/pca/PCA_without_scikit_learn.html">html file</a> -- <a href="https://colab.research.google.com/drive/1IWMuon3NSpGybmnBBWxlvbS9yUjxtf_8">open in colab</a>.</p></li></ul><h2 id="references">References <a href="#references" class="direct-link">#</a></h2><ul><li><strong>Luis Serrano</strong> -- [Video] <a href="https://www.youtube.com/watch?v=g-Hb26agBFg">Principal Component Analysis (PCA)</a>. It's very intuitive!</li><li><strong>Stats.StackExchange</strong> -- <a href="https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues">Making sense of principal component analysis, eigenvectors &amp; eigenvalues</a>.</li><li><strong>Scikit-learn</strong> -- <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">PCA official doc</a>.</li><li><strong>Tiep Vu</strong> -- <em>Principal Component Analysis</em>: <a href="https://machinelearningcoban.com/2017/06/15/pca/">B√†i 27</a> and <a href="https://machinelearningcoban.com/2017/06/21/pca2/">B√†i 28</a>.</li><li><strong>Jake VanderPlas</strong> -- <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html">In Depth: Principal Component Analysis</a>.</li><li><strong>Tutorial 4 Yang</strong> -- <a href="/files/ml/pca/tutorial4-yang.pdf">Principal Components Analysis</a>.</li><li><strong>Andrew NG.</strong> -- <a href="https://rawnote.dinhanhthi.com/machine-learning-coursera-8#principal-component-analysis-pca">My raw note</a> of the course <a href="https://www.coursera.org/learn/machine-learning/">"Machine Learning" on Coursera</a>.</li><li><strong>Shankar Muthuswamy</strong> -- <a href="https://shankarmsy.github.io/posts/pca-sklearn.html">Facial Image Compression and Reconstruction with PCA</a>.</li><li><strong>UFLDL - Stanford</strong> -- <a href="http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/">PCA Whitening</a>.</li></ul></div><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Principal Component Analysis (PCA)","image":["https://dinhanhthi.com/img/post/ML/PCA/pca-1.jpg","https://dinhanhthi.com/img/post/ML/PCA/pca-2.jpg","https://dinhanhthi.com/img/post/ML/PCA/pca-4.jpg","https://dinhanhthi.com/img/post/ML/PCA/pca-5.jpg","https://dinhanhthi.com/img/post/ML/PCA/pca-3.jpg","https://dinhanhthi.com/img/post/ML/PCA/pca-6.jpeg"],"author":"Anh-Thi DINH","genre":"Insert a schema.org genre","url":"https://dinhanhthi.com/principal-component-analysis/","mainEntityOfPage":"https://dinhanhthi.com/principal-component-analysis/","datePublished":"13-10-2019","dateModified":"03-12-2020","description":"What? # Sometimes we need to &amp;quot;compress&amp;quot; our data to speed up algorithms or to visualize data. One way is to use dimensionality..."}</script></article></main><footer><a href="/" target="_blank">Thi &nbsp;¬©&nbsp; 2020 </a>&nbsp;‚Ä¢&nbsp; <a href="/about-the-notes/">About the notes </a>&nbsp;‚Ä¢&nbsp; <a href="https://pobo.dinhanhthi.com" target="_blank">Po Bo </a>&nbsp;‚Ä¢&nbsp; <a href="/for-me-only/">For me only </a>&nbsp;‚Ä¢&nbsp; <a href="/donate/">Support Thi</a></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js"></script></body></html>