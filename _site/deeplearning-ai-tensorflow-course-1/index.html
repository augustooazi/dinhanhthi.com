<!DOCTYPE html><html domain=.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="default-src 'self';object-src 'none';script-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com/;style-src 'self' https://fonts.googleapis.com/ https://use.fontawesome.com/ 'unsafe-inline';img-src 'self' data:;font-src 'self' https://fonts.gstatic.com/ https://use.fontawesome.com/" http-equiv=Content-Security-Policy><link href=/favicon.svg rel=icon type=image/svg+xml><meta content=#f9c412 name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>TF 1 - Intro to TensorFlow for AI, ML, DL</title><meta content="TF 1 - Intro to TensorFlow for AI, ML, DL" property=og:title><meta content="This is my note for the first course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on..." name=description><meta content="This is my note for the first course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on..." property=og:description><meta content=summary_large_image name=twitter:card><meta content=@dinhanhthi name=twitter:site><meta content=@dinhanhthi name=twitter:creator><meta content=/img/header/tensorflow.svg property=og:image><link href=https://dinhanhthi.com/deeplearning-ai-tensorflow-course-1/ rel=canonical><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="ðŸ”¥ Anh-Thi DINH"><link href=/ rel=preconnect crossorigin=""><script src="/js/min.js?hash=70bdd86fac" async defer></script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))
      document
        .documentElement
        .classList
        .add('apple')</script><style>@charset "UTF-8";@font-face{font-display:swap;font-family:"Poppins";font-style:normal;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-regular.eot);src:local("Poppins Regular"),local("Poppins-Regular"),url(/fonts/poppins/poppins-v15-latin-regular.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-regular.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-regular.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-regular.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-regular.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:"Poppins";font-style:italic;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-italic.eot);src:local("Poppins Italic"),local("Poppins-Italic"),url(/fonts/poppins/poppins-v15-latin-italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:normal;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600.eot);src:local("Poppins SemiBold"),local("Poppins-SemiBold"),url(/fonts/poppins/poppins-v15-latin-600.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:italic;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600italic.eot);src:local("Poppins SemiBold Italic"),local("Poppins-SemiBoldItalic"),url(/fonts/poppins/poppins-v15-latin-600italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Recoleta';src:url(/fonts/recoleta/Recoleta-Bold.woff2) format("woff2"),url(/fonts/recoleta/Recoleta-Bold.woff) format("woff"),url(/fonts/poppins/Recoleta-Bold.ttf) format("truetype");font-weight:700;font-style:bold}*{border:0;box-sizing:border-box}:root{font-size:16.5px}main img{content-visibility:auto}::-webkit-scrollbar{height:10px;width:10px}::-webkit-scrollbar-thumb{background:#3e466b;border-radius:6px}::-webkit-scrollbar-thumb:hover{background:#aaa;cursor:pointer}::-webkit-scrollbar-track{background:#363948}::-webkit-scrollbar-corner{background:#282a36}body,html{font-family:"Poppins",Arial,Helvetica,sans-serif;font-size:16.5px}html{-webkit-text-size-adjust:100%}@supports (font-variation-settings:normal){html{font-family:"Poppins" var alt,Arial,Helvetica,sans-serif}}body{background:#282a36;color:#eee;margin:0;counter-reset:h2counter}strong{font-weight:600;color:#8cc8ff}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}a,a:hover{text-decoration:none}a:hover{border-bottom:2px solid #ffd479;color:#fff}a.no-effect:hover{border-bottom:none}img{max-width:100%}main{margin:0 auto}.page-note h3,.page-note>h2,h1,h2,h3{font-family:"Recoleta",Arial,Helvetica,sans-serif}h1{font-size:29.7px}h2{font-size:24.75px}h3{font-size:21.5325px}.page-note h3,.page-note>h2{color:#eee}.page-note h3:hover .direct-link,.page-note>h2:hover .direct-link{display:inline-block}.page-note h3:hover a:hover,.page-note>h2:hover a:hover,a{color:#ffd479}.page-note>h2{font-size:24.75px;margin:37.125px 0 19.8px}.page-note p+ol,.page-note p+ul,.page-note>h2+h3{margin-top:-.5rem}.page-note>h3{font-size:21.5325px;margin-bottom:19.8px}.page-note .direct-link{display:none;color:#777;border-bottom:none;margin-left:3px}.page-note pre+h2,.page-note pre+h3,.page-note>h3{margin-top:37.125px}.page-note h1{counter-reset:h2counter}.page-note h2{counter-reset:h3counter}.page-note h3{counter-reset:h4counter}.page-note h3:before{opacity:.5;content:counter(h2counter) "." counter(h3counter) ".Â Â ";counter-increment:h3counter}.page-note h2:before{content:counter(h2counter) ".Â Â ";counter-increment:h2counter;color:#8cc8ff}.container,header{width:100%;margin:0 auto}.normal{padding:0 16.5px;width:100%}@media (min-width:916.5px){.normal{width:900px}}.mt-2{margin-top:2rem}.page-index .container{padding:2rem 1rem 0}.page-index .main-cats{flex:0 1 calc(100% - 280px);padding-right:1rem}.page-index .main-cats>.category-wrapper{padding-bottom:1.5rem}.page-index .main-cats>.category-wrapper>.category{border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:2rem 1.5rem 1.5rem}.page-index .toc-index{border:1px solid #404040;border-radius:7px;height:fit-content;background:#35373c;flex:0 1 280px;position:sticky;top:60px;padding:1rem 1.1rem}.page-index .toc-index h3{padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 10px;font-size:1.3rem}.page-index .toc-index ul{padding-left:20px;margin:0}.page-index .toc-index p{font-style:italic;color:#999;padding-top:0;margin-bottom:0;font-size:.95rem;margin-top:10px}.page-index .toc-index p a{color:#999;border-bottom:2px solid #999}.page-index .toc-index p a:hover{border-bottom:2px solid #ffd479}@media (max-width:991px){.page-index .main-cats{flex:1 1 100%;order:2;padding-right:0}.page-index .toc-index{flex:1 1 100%;order:1;position:inherit;margin-bottom:1.5rem}.page-index .toc-index ul{column-count:3;-webkit-column-count:3;-moz-column-count:3}}@media (max-width:767px){.page-index .toc-index ul{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (max-width:575px){.page-index .toc-index ul{column-count:1;-webkit-column-count:1;-moz-column-count:1}}.category{width:100%}.category h2,header h1{font-size:1.55rem;margin-top:0}.category h2 img{float:left;margin-right:7px}.category .list-homepage{list-style:none;padding-left:10px;margin-bottom:0;column-count:1;-webkit-column-count:1;-moz-column-count:1}@media (min-width:768px){.category .list-homepage{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (min-width:992px){.category .list-homepage{column-count:3;-webkit-column-count:3;-moz-column-count:3}}.category .list-homepage li{padding-left:15px;margin-bottom:10px;display:inline-block;width:100%}.category .list-homepage li a{color:#ddd;border-bottom:2px solid rgba(255,255,255,.14);border-style:dotted}.category .list-homepage li::before{content:"ðŸ“„";margin-right:5px;margin-left:-25px;opacity:.8}.category .list-homepage li:hover,.hsbox .hs__title{cursor:pointer}.category .list-homepage li:hover a{border-color:#ffd479;color:#fff}.category .list-homepage li:hover::before{opacity:1}.page-index header{padding-top:4em}.page-index header .header-logo{height:80px;width:auto}header nav{z-index:10}#nav{z-index:2;position:relative}header{padding:5.5rem 1.5rem 1rem;width:900px;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header h1{font-size:2.2rem;margin-bottom:0}header p{margin-top:1rem}header .header-logo{width:55px;height:55px;margin-bottom:1rem}header .header-logo img{width:100%;height:100%}header .social{margin-top:.5rem}header #more-info #note-tag>a,header .social a{margin-right:10px}header .social a:last-child{margin-right:0}@media (min-width:992px){header .social a{margin-right:20px}}header .social a img{border-radius:50%}header #more-info{padding:1rem}header #more-info #note-tag{padding-bottom:10px;border-bottom:1px solid #444}header #more-info #note-tag>a::before{content:"#"}header #more-info #last-modified{padding-top:10px;font-style:italic}#reading-progress,nav{top:0;left:0;width:100vw}#reading-progress{z-index:3;border-bottom:1px solid #ffd479;position:absolute;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}.intro,.job span{font-size:1.02rem}.intro b,.intro strong{color:#ffd479;font-weight:400}.intro a,footer a:hover{color:#fff}.job span{background:#ffd479;color:#000;padding:3px 10px;border-radius:15px}nav{position:fixed;padding:0 1.5em;background:#35373c}@media (max-width:992px){nav{padding:0 1em}}@media (max-width:576px){nav{padding:0 .5em}}nav #nav{display:-ms-flexbox;-ms-flex-align:center;align-items:center}nav #nav a{color:#ccc;margin-right:15px;align-items:center;padding:0 .5rem;font-size:1.1rem;white-space:nowrap}nav #nav a img{margin-right:5px}nav #nav a:hover{color:#fff;cursor:pointer;text-decoration:none}nav #nav .nav-item{text-align:left;margin-right:5px}@media (min-width:421px){nav #nav .nav-item{padding-left:0!important}}@media (max-width:575px){nav #nav .nav-item{width:unset!important}nav #nav .nav-item span{display:none}}@media (min-width:576px){nav #nav .nav-item{margin-right:15px}}nav #nav .nav-github{text-align:right;padding-right:0!important;margin-right:0!important}nav #nav .nav-search{display:block;background-image:linear-gradient(to right,#3d4251,#3b3f4c,#393d46,#373a41,#35373c);width:100%;position:relative}nav #nav,nav #nav .nav-search form,nav #nav a{display:flex}nav #nav .nav-search .nav-search-input{border:0;background:0 0;color:#ddd;font-size:1.05rem;padding:.65rem .5rem;width:100%}nav #nav .nav-search .nav-search-input:focus{outline:0;border:0}nav #nav .nav-search #search-result{position:absolute;max-height:80vh;overflow:auto;width:100%;background:#35373c;border-bottom-right-radius:5px;border-bottom-left-radius:5px;padding:0 1rem}@media (max-width:767px){nav #nav .nav-search #search-result{position:fixed;left:0;right:0;border-radius:0}}nav #nav .nav-search #search-result ul#searchResults{padding:0 0 0 20px}.page-note ol li,.page-note ul li,div.toc ol li,nav #nav .nav-search #search-result ul#searchResults li h3{margin-bottom:5px}nav #nav .nav-search #search-result ul#searchResults li h3 a{color:#efb232;white-space:inherit;padding:0;text-align:left;font-weight:400;font-size:16.5px;font-family:"Poppins",Arial,Helvetica,sans-serif;line-height:1.4}nav #nav .nav-search #search-result ul#searchResults li h3 a:hover{border-bottom:none;color:#8cc8ff}nav #nav .nav-search #search-result ul#searchResults li p{text-align:left;margin-top:0;line-height:1.4}nav #nav .nav-search #search-result #noResultsFound p{text-align:left}footer{font-size:1.1rem;background:#35373c;padding:.75rem 1rem;text-align:center;margin-top:3rem}footer a{color:#ccc}.hsbox{margin-bottom:24.75px;border:1px solid #969696;padding:1rem;border-radius:3px}.hsbox .hs__title::before{content:" ";display:inline-block;border-top:7px solid transparent;border-bottom:7px solid transparent;border-left:7px solid currentColor;vertical-align:middle;margin-right:.7rem;transform:translateY(-2px);transition:transform .2s ease-out}.hsbox .hs__title.show{padding-bottom:15px;border-bottom:.5px solid #666;margin-bottom:1rem}.hsbox .hs__title.show+.hs__content{display:block;opacity:1;padding:5px 0;transition:all .25s 0s cubic-bezier(.4,0,.2,1)}.hsbox .hs__title.show::before{transform:rotate(90deg) translateX(-3px)}.hsbox .hs__content{display:none;transition:all .2s 0s ease}.hsbox .hs__content>:last-child{margin-bottom:0}.page-note .text-center{text-align:center}.page-note ol,.page-note p,.page-note ul{margin-top:0;margin-bottom:24.75px}.page-note ol li ol,.page-note ol li ul,.page-note ul li ol,.page-note ul li ul{margin-bottom:5px;padding-left:20px}.page-note ol li>*,.page-note ul li>*{margin-bottom:10px}.page-note p.noindent{display:none;padding-left:20px}.page-note p.noindent+ol,.page-note p.noindent+ul{padding-left:20px}.page-note p.indent{display:none;padding-left:40px}.page-note ol.indent,.page-note p.indent+ol,.page-note p.indent+ul,.page-note ul.indent{padding-left:40px}.page-note ol.noindent,.page-note ul.noindent{padding-left:20px}.page-note hr{border-bottom:1px solid #676767;margin-bottom:24.75px}#reading-list .item .author{font-style:italic}#reading-list .item .intro{color:#999}code[class*=language-],pre[class*=language-]{color:#eee;font-size:16px;text-shadow:none;font-family:Menlo,Monaco,Consolas,"Andale Mono","Ubuntu Mono","Courier New",monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#75a7ca}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}.token.comment{color:#6a9955}.token.punctuation{color:#eee}.token.inserted,.token.number{color:#b5cea8}.token.builtin,.token.string{color:#ce9178}.token.operator{color:#eee}.token.keyword{color:#90cdff}.token.function{color:#efefac}.token.class-name{color:#4ec9b0}.token.boolean{color:#90cdff}.token.property{color:#9cdcfe}pre[class*=language-]>code[class*=language-]{position:relative;z-index:1}code,pre{font-family:Consolas,Menlo,Monaco,"Andale Mono WT","Andale Mono","Lucida Console","Lucida Sans Typewriter","DejaVu Sans Mono","Bitstream Vera Sans Mono","Liberation Mono","Nimbus Mono L","Courier New",Courier,monospace;line-height:1.5}h2>code{font-size:21.78px!important}h3>code{font-size:18.9486px!important}:not(pre)>code{border:1px solid #444;background:#6b444245;padding:2px 4px;margin:0 1px;border-radius:3px;font-size:.9rem;color:#fff;word-break:break-word}h2>code,h3>code{color:#ddd;padding-right:6px}a>code{color:#ffd479}a:hover>code{color:#ccc}pre,pre[class*=language-]{margin:0 0 27.225px;overflow:auto}pre>code,pre[class*=language-]>code{display:block;padding:14.5px 16.5px 16.5px;background:#2f3240;border:.5px solid #3b3e54;overflow:auto;border-radius:3px;max-height:450px}div.toc{margin-bottom:24.75px;border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:15px 15px 10px 0}div.toc>ol::before{content:"In this note";display:block;padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 15px;font-size:1.18rem;font-family:"Recoleta",Arial,Helvetica,sans-serif}div.toc ol{padding-left:20px;font-size:14.85px;margin-bottom:0}div.toc ol li code{font-size:.85rem;background:#ececec;padding:0 4px 2px}div.toc ol li ol{padding-left:10px;margin-top:7px}div.toc ol,div.toc ol ol{counter-reset:item;list-style-type:none}div.toc ol li::before{content:counters(item,".") ". ";counter-increment:item}div.toc>ol>li ol>li::before{opacity:.7}div.toc>ol>li::before{color:#8cc8ff}@media (min-width:1300px){div.toc{float:right;margin-right:-280px;border-left:none;width:250px;position:-webkit-sticky;position:sticky;top:60px;max-height:70vh;overflow:auto}div.toc ol{margin-top:0;margin-bottom:0}}@media (min-width:1500px){div.toc{margin-right:-310px;width:280px}}.toc-active>a{color:#fff!important}.toc-active::before{opacity:1!important}.page-note img{height:auto;width:100%}@media (min-width:768px){.page-note .img-100,.page-note .img-30,.page-note .img-40{width:30%;margin-left:auto;margin-right:auto;display:block}.page-note .img-100,.page-note .img-40{width:40%}.page-note .img-100{width:100%}}.page-note p>img+br,.page-note p>picture+br{display:none}.page-note p>img+br+em,.page-note p>picture+br+em{display:block;text-align:center;margin-top:10px}</style><header><nav><div id=nav><a href=/ class="nav-item no-effect"><img alt=home src=/img/nav/home.svg height=18 width=18> <span>Thi</span> </a><a href=/about/ class="nav-item no-effect"><img alt=about src=/img/nav/about.svg height=15 width=15> <span>About</span></a><div class=nav-search><form><input aria-label="search notes..." class=nav-search-input id=searchField placeholder="search notes..." type=search></form><div id=search-result style="display: none;"><ul id=searchResults></ul><div id=noResultsFound style="display: none;"><p>No results found.</div></div></div><a href=https://github.com/dinhanhthi class="nav-item no-effect nav-github" target=_blank><img alt=github src=/img/nav/github.svg height=20 width=20></a></div><div id=reading-progress aria-hidden=true></div></nav><div class=header-logo><img alt="TF 1 - Intro to TensorFlow for AI, ML, DL" src=/img/header/tensorflow.svg></div><h1>TF 1 - Intro to TensorFlow for AI, ML, DL</h1><div id=more-info><div id=note-tag><a href=/tags/mooc>MOOC</a> <a href=/tags/deeplearning.ai>deeplearning.ai</a> <a href=/tags/deep-learning>Deep Learning</a> <a href=/tags/tensorflow>TensorFlow</a></div><div id=last-modified>03-12-2020</div></div></header><main><article><div class="container mt-2 normal page-note"><div class=toc><ol><li><a href=#basic-dl-on-mnist>Basic DL on MNIST</a><li><a href=#basic-dl-on-fashion-mnist>Basic DL on Fashion-MNIST</a><li><a href=#basic-cnn-on-fashion-mnist>Basic CNN on Fashion-MNIST</a><li><a href=#visualizing-the-convolutions-and-pooling>Visualizing the Convolutions and Pooling</a><li><a href=#using-real-world-images>Using real-world images</a><ol><li><a href=#imagegenerator>ImageGenerator</a><li><a href=#convnet-with-imagegenerator>ConvNet with ImageGenerator</a></ol></ol></div><p>This is my note for the <a href=https://www.coursera.org/learn/introduction-tensorflow>first course</a> of <a href=https://www.coursera.org/specializations/tensorflow-in-practice>TensorFlow in Practice Specialization</a> given by <a href=http://deeplearning.ai/ >deeplearning.ai</a> and taught by Laurence Moroney on Coursera.<p>ðŸ‘‰ Check the codes <a href=https://github.com/dinhanhthi/deeplearning.ai-courses/tree/master/TensorFlow%20in%20Practice>on my Github</a>.<br>ðŸ‘‰ Official <a href=https://github.com/lmoroney/dlaicourse>notebooks</a> on Github.<p>ðŸ‘‰ Go to <a href=/deeplearning-ai-tensorflow-course-2>course 2 - CNN in Tensorflow</a>.<br>ðŸ‘‰ Go to <a href=/deeplearning-ai-tensorflow-course-3>course 3 - NLP in Tensorflow</a>.<br>ðŸ‘‰ Go to <a href=/deeplearning-ai-tensorflow-course-4>course 4 - Sequences, Time Series and Prediction</a>.<h2 id=basic-dl-on-mnist>Basic DL on MNIST <a href=#basic-dl-on-mnist class=direct-link>#</a></h2><pre class=language-python><code class=language-python><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<br><br><span class="token comment"># stop the training with condition</span><br><span class="token keyword">class</span> <span class="token class-name">myCallback</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>Callback<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token keyword">def</span> <span class="token function">on_epoch_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> logs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># compare at the end of each epoch</span><br>        <span class="token keyword">if</span><span class="token punctuation">(</span>logs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>stop_training <span class="token operator">=</span> <span class="token boolean">True</span><br><br>mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<br><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><br>x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> x_test <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token comment"># normalize</span><br><br>callbacks <span class="token operator">=</span> myCallback<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># define the callback</span><br><br>model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span><br>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># Takes that square and</span><br>                                                   <span class="token comment"># turns it into a 1 dim</span><br>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span><br>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">)</span> <span class="token comment"># 10 outputs</span><br><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span><br>              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span><br>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span><span class="token punctuation">[</span>callbacks<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p><strong>Comments</strong> (<a href=https://bit.ly/3jHSCYg>notebook</a>):<p class=indent><ol><li>Adding more Neurons we have to do more calculations, slowing down the process, but get more accurate.<li>The first layer in your network should be the same shape as your data.<li>The number of neurons in the last layer should match the number of classes you are classifying for.<li>Extra layers are often necessary.<li><strong>Flatten</strong> as the name implies, converts your multidimensional matrices (<code>Batch.Size x Img.W x Img.H x Kernel.Size</code>) to a nice single 2-dimensional matrix: (<code>Batch.Size x (Img.W x Img.H x Kernel.Size)</code>). During backpropagation it also converts back your delta of size (<code>Batch.Size x (Img.W x Img.H x Kernel.Size)</code>) to the original (<code>Batch.Size x Img.W x Img.H x Kernel.Size</code>).<li><strong>Dense layer</strong> is of course the standard fully connected layer.</ol><p><img alt="CNN layers" src=/img/post/mooc/tf/cnn-layers.png class="img-100 pop"><br><em>CNN layers, <a href=mdpi.com>cource of image</a>.</em><h2 id=basic-dl-on-fashion-mnist>Basic DL on Fashion-MNIST <a href=#basic-dl-on-fashion-mnist class=direct-link>#</a></h2><pre class=language-python><code class=language-python><span class="token comment"># the same as in MINST</span><br><span class="token comment"># different at below line of loading data</span><br>mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>fashion_mnist</code></pre><h2 id=basic-cnn-on-fashion-mnist>Basic CNN on Fashion-MNIST <a href=#basic-cnn-on-fashion-mnist class=direct-link>#</a></h2><pre class=language-python><code class=language-python><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<br>mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>fashion_mnist<br><br><span class="token keyword">class</span> <span class="token class-name">myCallback</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>Callback<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token keyword">def</span> <span class="token function">on_epoch_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> logs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">:</span><br>        <span class="token keyword">if</span><span class="token punctuation">(</span>logs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> logs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">0.998</span><span class="token punctuation">)</span> <span class="token punctuation">:</span><br>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nReached 99.8% accuracy so cancelling training!'</span><span class="token punctuation">)</span><br>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>stop_training <span class="token operator">=</span> <span class="token boolean">True</span><br><br><span class="token punctuation">(</span>training_images<span class="token punctuation">,</span> training_labels<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><br><span class="token comment"># Why reshape?</span><br><span class="token comment"># The first convolution expects a single tensor containing everything,</span><br><span class="token comment"># so instead of 60000 28x28x1 items in a list, we have a single 4D list</span><br><span class="token comment"># that is 60000x28x28x1</span><br><span class="token comment">#</span><br><span class="token comment"># training_images' shape (before reshape): (60000, 28, 28)</span><br><span class="token comment"># training_images' shape (after reshape): (60000, 28, 28, 1)</span><br><span class="token comment"># trainaing_labels' shape: (60000,)</span><br>training_images<span class="token operator">=</span>training_images<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><br>training_images<span class="token operator">=</span>training_images <span class="token operator">/</span> <span class="token number">255.0</span><br>test_images <span class="token operator">=</span> test_images<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><br>test_images<span class="token operator">=</span>test_images<span class="token operator">/</span><span class="token number">255.0</span><br><br>model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><br><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span><br>              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span><br>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>callbacks <span class="token operator">=</span> myCallback<span class="token punctuation">(</span><span class="token punctuation">)</span><br><br>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>training_images<span class="token punctuation">,</span> training_labels<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span><span class="token punctuation">[</span>callbacks<span class="token punctuation">]</span><span class="token punctuation">)</span><br>test_loss <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span></code></pre><pre class=language-bash><code class=language-bash>model.summary<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># model detail</span></code></pre><pre class=language-bash><code class=language-bash>Model: <span class="token string">"sequential_1"</span><br>_________________________________________________________________<br>Layer <span class="token punctuation">(</span>type<span class="token punctuation">)</span>                 Output Shape              Param <span class="token comment">#</span><br><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><br>conv2d <span class="token punctuation">(</span>Conv2D<span class="token punctuation">)</span>              <span class="token punctuation">(</span>None, <span class="token number">26</span>, <span class="token number">26</span>, <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token number">640</span><br>                             <span class="token comment"># for every image, 64 convolution has been tried</span><br>                             <span class="token comment"># 26 (=28-2) because we use 3x3 filter and we can't</span><br>                             <span class="token comment"># count on edges, so the picture is 2 smaller on x and y.</span><br>                             <span class="token comment"># if 5x5 filter => 4 smaller on x and y.</span><br>_________________________________________________________________<br>max_pooling2d <span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">)</span> <span class="token punctuation">(</span>None, <span class="token number">13</span>, <span class="token number">13</span>, <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token number">0</span><br>_________________________________________________________________<br>conv2d_1 <span class="token punctuation">(</span>Conv2D<span class="token punctuation">)</span>            <span class="token punctuation">(</span>None, <span class="token number">11</span>, <span class="token number">11</span>, <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token number">36928</span><br>_________________________________________________________________<br>max_pooling2d_1 <span class="token punctuation">(</span>MaxPooling2 <span class="token punctuation">(</span>None, <span class="token number">5</span>, <span class="token number">5</span>, <span class="token number">64</span><span class="token punctuation">)</span>          <span class="token number">0</span><br>_________________________________________________________________<br>flatten_1 <span class="token punctuation">(</span>Flatten<span class="token punctuation">)</span>          <span class="token punctuation">(</span>None, <span class="token number">1600</span><span class="token punctuation">)</span>              <span class="token number">0</span><br>_________________________________________________________________<br>dense_2 <span class="token punctuation">(</span>Dense<span class="token punctuation">)</span>              <span class="token punctuation">(</span>None, <span class="token number">128</span><span class="token punctuation">)</span>               <span class="token number">204928</span><br>_________________________________________________________________<br>dense_3 <span class="token punctuation">(</span>Dense<span class="token punctuation">)</span>              <span class="token punctuation">(</span>None, <span class="token number">10</span><span class="token punctuation">)</span>                <span class="token number">1290</span><br><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><br>Total params: <span class="token number">243,786</span><br>Trainable params: <span class="token number">243,786</span><br>Non-trainable params: <span class="token number">0</span></code></pre><p>Refs:<p class=indent><ol><li><a href=https://en.wikipedia.org/wiki/Kernel_(image_processing)>Kernel in image processing</a>: examples with images.<li><a href=https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer>Pooling layer</a>: non-linear down-sampling.</ol><p>More?<p class=indent><ol><li><p><a href=https://lodev.org/cgtutor/filtering.html>Image Filtering</a> -- Lode's Computer Graphics Tutorial<li><p>Applying Convolutions on top of our Deep neural network will make training => It depends on many factors. It might make your training faster or slower, and a poorly designed Convolutional layer may even be less efficient than a plain DNN!<li><p><strong>What is a Convolution?</strong> => A technique to isolate features in images<li><p><strong>What is a Pooling?</strong> => A technique to reduce the information in an image while maintaining features<li><p>How do Convolutions improve image recognition? => They isolate features in images<li><p>After passing a 3x3 conv filter over a 28x28 image, how big will the output be? => 26x26<p><img alt="3x3 conv kernel" src=/img/post/mooc/tf/conv_ker_3x3.gif class=img-30><br><em>7x7 to 5x5 (<a href=https://iamaaditya.github.io/2016/03/one-by-one-convolution/ >source</a>)</em><li><p>After max pooling a 26x26 image with a 2x2 filter, how big will the output be? => 13x13<p><img alt="max pooling idea" src=/img/post/mooc/tf/max-pooling.jpg class=img-40><br><em>(<a href=https://deepai.org/machine-learning-glossary-and-terms/max-pooling>source</a>)</em></ol><h2 id=visualizing-the-convolutions-and-pooling>Visualizing the Convolutions and Pooling <a href=#visualizing-the-convolutions-and-pooling class=direct-link>#</a></h2><p>Using layer API, something like below, check more in <a href=https://bit.ly/3f6wQtA>the notebook</a>.<pre class=language-python><code class=language-python><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<br>f<span class="token punctuation">,</span> axarr <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span><br><br><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> models<br>layer_outputs <span class="token operator">=</span> <span class="token punctuation">[</span>layer<span class="token punctuation">.</span>output <span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">]</span><br>activation_model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">,</span> outputs <span class="token operator">=</span> layer_outputs<span class="token punctuation">)</span><br><br><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    f1 <span class="token operator">=</span> activation_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_images<span class="token punctuation">[</span>FIRST_IMAGE<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><br>    axarr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>x<span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>f1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> CONVOLUTION_NUMBER<span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'inferno'</span><span class="token punctuation">)</span><br>    axarr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>x<span class="token punctuation">]</span><span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><br>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></code></pre><h2 id=using-real-world-images>Using real-world images <a href=#using-real-world-images class=direct-link>#</a></h2><p>An example of classifying horses and humans!<h3 id=imagegenerator>ImageGenerator <a href=#imagegenerator class=direct-link>#</a></h3><p>ðŸ‘‰ <a href=https://www.coursera.org/lecture/introduction-tensorflow/understanding-imagegenerator-kqRHk>Video explain ImageGenerator</a>.<pre class=language-python><code class=language-python><span class="token comment"># make images more used for training</span><br><span class="token comment"># (focus on object, split cleary objects, label images,...)</span><br><span class="token comment"># also help to augmenting data (rotate, skew, flip,...)</span><br><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator<br><br>train_datagen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span><br>    <span class="token comment"># normalize -> No need to convert images and then put in the training</span><br>    <span class="token comment"># do the scaling on the fly</span><br>train_generator <span class="token operator">=</span> train_datagen<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span><br>    train_dir<span class="token punctuation">,</span> <span class="token comment"># dir contains the dir containing your images</span><br>               <span class="token comment"># -> be careful!</span><br>    target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># images will be resized when loaded, genial!</span><br>                            <span class="token comment"># because NN always needs that!</span><br>                            <span class="token comment"># -> experimenting with diff sizes without</span><br>                            <span class="token comment"># impacting your source data</span><br>    batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span><br>    class_mode<span class="token operator">=</span><span class="token string">"binary"</span>     <span class="token comment"># 2 diff things</span><br><span class="token punctuation">)</span><br><br>test_datagen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token comment"># normalize</span><br>validation_generator <span class="token operator">=</span> test_datagen<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span><br>    validation_dir<span class="token punctuation">,</span> <span class="token comment"># dir contains the dir containing your images</span><br>    target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>    batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span><br>    class_mode<span class="token operator">=</span><span class="token string">"binary"</span><br><span class="token punctuation">)</span></code></pre><h3 id=convnet-with-imagegenerator>ConvNet with ImageGenerator <a href=#convnet-with-imagegenerator class=direct-link>#</a></h3><p>More docs:<p class=indent><ul><li><a href=https://gombru.github.io/2018/05/23/cross_entropy_loss/ >Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names</a><li><a href=http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>Overview of mini-batch gradient descent</a></ul></div><script type=application/ld+json>{
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "TF 1 - Intro to TensorFlow for AI, ML, DL",
        "image": [],
        "author": "Anh-Thi DINH",
        "genre": "Insert a schema.org genre",
        "url": "https://dinhanhthi.com/deeplearning-ai-tensorflow-course-1/",
        "mainEntityOfPage": "https://dinhanhthi.com/deeplearning-ai-tensorflow-course-1/",
        "datePublished": "25-07-2020",
        "dateModified": "03-12-2020",
        "description": "This is my note for the first course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on..."
      }</script></article></main><footer><a href=/ target=_blank>Thi Â Â©Â  2020 </a>Â â€¢Â  <a href=/about-the-notes/ >About the notes </a>Â â€¢Â  <a href=https://pobo.dinhanhthi.com target=_blank>Po Bo </a>Â â€¢Â  <a href=/for-me-only/ >For me only </a>Â â€¢Â  <a href=/donate/ >Support Thi</a></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js></script>