<!DOCTYPE html><html domain=.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="default-src 'self';object-src 'none';script-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com/;style-src 'self' https://fonts.googleapis.com/ https://use.fontawesome.com/ 'unsafe-inline';img-src 'self' data:;font-src 'self' https://fonts.gstatic.com/ https://use.fontawesome.com/" http-equiv=Content-Security-Policy><link href=/favicon.svg rel=icon type=image/svg+xml><meta content=#f9c412 name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>Docker + GPUs</title><meta content="Docker + GPUs" property=og:title><meta content="ðŸ‘‰ Docker note. WSL + Windows # Make WSL2 recognize GPU on Windows 10 ðŸ‘‰ Check this tut. If you meet error &amp;quot;Your insider preview build..." name=description><meta content="ðŸ‘‰ Docker note. WSL + Windows # Make WSL2 recognize GPU on Windows 10 ðŸ‘‰ Check this tut. If you meet error &amp;quot;Your insider preview build..." property=og:description><meta content=summary_large_image name=twitter:card><meta content=@dinhanhthi name=twitter:site><meta content=@dinhanhthi name=twitter:creator><meta content=/img/header/docker.svg property=og:image><link href=https://dinhanhthi.com/docker-gpu/ rel=canonical><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="ðŸ”¥ Anh-Thi DINH"><link href=/ rel=preconnect crossorigin=""><script src="/js/min.js?hash=70bdd86fac" async defer></script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))
      document
        .documentElement
        .classList
        .add('apple')</script><style>@charset "UTF-8";@font-face{font-display:swap;font-family:"Poppins";font-style:normal;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-regular.eot);src:local("Poppins Regular"),local("Poppins-Regular"),url(/fonts/poppins/poppins-v15-latin-regular.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-regular.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-regular.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-regular.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-regular.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:"Poppins";font-style:italic;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-italic.eot);src:local("Poppins Italic"),local("Poppins-Italic"),url(/fonts/poppins/poppins-v15-latin-italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:normal;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600.eot);src:local("Poppins SemiBold"),local("Poppins-SemiBold"),url(/fonts/poppins/poppins-v15-latin-600.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:italic;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600italic.eot);src:local("Poppins SemiBold Italic"),local("Poppins-SemiBoldItalic"),url(/fonts/poppins/poppins-v15-latin-600italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Recoleta';src:url(/fonts/recoleta/Recoleta-Bold.woff2) format("woff2"),url(/fonts/recoleta/Recoleta-Bold.woff) format("woff"),url(/fonts/poppins/Recoleta-Bold.ttf) format("truetype");font-weight:700;font-style:bold}*{border:0;box-sizing:border-box}:root{font-size:16.5px}main img{content-visibility:auto}::-webkit-scrollbar{height:10px;width:10px}::-webkit-scrollbar-thumb{background:#3e466b;border-radius:6px}::-webkit-scrollbar-thumb:hover{background:#aaa;cursor:pointer}::-webkit-scrollbar-track{background:#363948}::-webkit-scrollbar-corner{background:#282a36}body,html{font-family:"Poppins",Arial,Helvetica,sans-serif;font-size:16.5px}html{-webkit-text-size-adjust:100%}@supports (font-variation-settings:normal){html{font-family:"Poppins" var alt,Arial,Helvetica,sans-serif}}body{background:#282a36;color:#eee;margin:0;counter-reset:h2counter}strong{font-weight:600;color:#8cc8ff}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}mark{color:inherit;padding:0;background-color:transparent;box-shadow:inset 0 -4px 0 0 #ffd479}a,a:hover{text-decoration:none}a:hover{border-bottom:2px solid #ffd479;color:#fff}a.no-effect:hover{border-bottom:none}img{max-width:100%}main{margin:0 auto}.page-note>h2,h1,h2{font-family:"Recoleta",Arial,Helvetica,sans-serif;font-size:24.75px}.page-note>h2,h1{font-size:29.7px}.page-note>h2{color:#eee;font-size:24.75px;margin:37.125px 0 19.8px}.page-note>h2:hover .direct-link{display:inline-block}.page-note>h2:hover a:hover,a{color:#ffd479}.page-note .direct-link{display:none;color:#777;border-bottom:none;margin-left:3px}.page-note pre+h2{margin-top:37.125px}.page-note h1{counter-reset:h2counter}.page-note h2{counter-reset:h3counter}.page-note h2:before{content:counter(h2counter) ".Â Â ";counter-increment:h2counter;color:#8cc8ff}.container,header{width:100%;margin:0 auto}.normal{padding:0 16.5px;width:100%}@media (min-width:916.5px){.normal{width:900px}}.mt-2{margin-top:2rem}.page-index .container{padding:2rem 1rem 0}.page-index .main-cats{flex:0 1 calc(100% - 280px);padding-right:1rem}.page-index .main-cats>.category-wrapper{padding-bottom:1.5rem}.page-index .main-cats>.category-wrapper>.category{border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:2rem 1.5rem 1.5rem}.page-index .toc-index{border:1px solid #404040;border-radius:7px;height:fit-content;background:#35373c;flex:0 1 280px;position:sticky;top:60px;padding:1rem 1.1rem}.page-index .toc-index h3{padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 10px;font-size:1.3rem}.page-index .toc-index ul{padding-left:20px;margin:0}.page-index .toc-index p{font-style:italic;color:#999;padding-top:0;margin-bottom:0;font-size:.95rem;margin-top:10px}.page-index .toc-index p a{color:#999;border-bottom:2px solid #999}.page-index .toc-index p a:hover{border-bottom:2px solid #ffd479}@media (max-width:991px){.page-index .main-cats{flex:1 1 100%;order:2;padding-right:0}.page-index .toc-index{flex:1 1 100%;order:1;position:inherit;margin-bottom:1.5rem}.page-index .toc-index ul{column-count:3;-webkit-column-count:3;-moz-column-count:3}}@media (max-width:767px){.page-index .toc-index ul{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (max-width:575px){.page-index .toc-index ul{column-count:1;-webkit-column-count:1;-moz-column-count:1}}.category{width:100%}.category h2,header h1{font-size:1.55rem;margin-top:0}.category h2 img{float:left;margin-right:7px}.category .list-homepage{list-style:none;padding-left:10px;margin-bottom:0;column-count:1;-webkit-column-count:1;-moz-column-count:1}@media (min-width:768px){.category .list-homepage{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (min-width:992px){.category .list-homepage{column-count:3;-webkit-column-count:3;-moz-column-count:3}}.category .list-homepage li{padding-left:15px;margin-bottom:10px;display:inline-block;width:100%}.category .list-homepage li a{color:#ddd;border-bottom:2px solid rgba(255,255,255,.14);border-style:dotted}.category .list-homepage li::before{content:"ðŸ“„";margin-right:5px;margin-left:-25px;opacity:.8}.category .list-homepage li:hover{cursor:pointer}.category .list-homepage li:hover a{border-color:#ffd479;color:#fff}.category .list-homepage li:hover::before{opacity:1}.page-index header{padding-top:5em;padding-bottom:0}.page-index header .header-logo{height:80px;width:auto}header nav{z-index:10}#nav{z-index:2;position:relative}header{padding:5.5rem 1.5rem 1rem;width:900px;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header h1{font-size:2.2rem;margin-bottom:0}header p{margin-top:1rem}header .header-logo{width:55px;height:55px;margin-bottom:1rem}header .header-logo img{width:100%;height:100%}header .social{margin-top:.5rem}header #more-info #note-tag>a,header .social a{margin-right:10px}header .social a:last-child{margin-right:0}@media (min-width:992px){header .social a{margin-right:20px}}header .social a img{border-radius:50%}header #more-info{padding:1rem}header #more-info #note-tag{padding-bottom:10px;border-bottom:1px solid #444}header #more-info #note-tag>a::before{content:"#"}header #more-info #last-modified{padding-top:10px;font-style:italic}#reading-progress,nav{top:0;left:0;width:100vw}#reading-progress{z-index:3;border-bottom:1px solid #ffd479;position:absolute;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}.intro,.job span{font-size:1.02rem}.intro b,.intro strong{color:#ffd479;font-weight:400}.intro a,footer a:hover{color:#fff}.job span{background:#ffd479;color:#000;padding:3px 10px;border-radius:15px}nav{position:fixed;padding:0 1.5em;background:#35373c}@media (max-width:992px){nav{padding:0 1em}}@media (max-width:576px){nav{padding:0 .5em}}nav #nav{display:-ms-flexbox;-ms-flex-align:center;align-items:center}nav #nav a{color:#ccc;margin-right:15px;align-items:center;padding:0 .5rem;font-size:1.1rem;white-space:nowrap}nav #nav a img{margin-right:5px}nav #nav a:hover{color:#fff;cursor:pointer;text-decoration:none}nav #nav .nav-item{text-align:left;margin-right:5px}@media (min-width:421px){nav #nav .nav-item{padding-left:0!important}}@media (max-width:575px){nav #nav .nav-item{width:unset!important}nav #nav .nav-item span{display:none}}@media (min-width:576px){nav #nav .nav-item{margin-right:15px}}nav #nav .nav-github{text-align:right;padding-right:0!important;margin-right:0!important}nav #nav .nav-search{display:block;background-image:linear-gradient(to right,#3d4251,#3b3f4c,#393d46,#373a41,#35373c);width:100%;position:relative}nav #nav,nav #nav .nav-search form,nav #nav a{display:flex}nav #nav .nav-search .nav-search-input{border:0;background:0 0;color:#ddd;font-size:1.05rem;padding:.65rem .5rem;width:100%}nav #nav .nav-search .nav-search-input:focus{outline:0;border:0}nav #nav .nav-search #search-result{position:absolute;max-height:80vh;overflow:auto;width:100%;background:#35373c;border-bottom-right-radius:5px;border-bottom-left-radius:5px;padding:0 1rem}@media (max-width:767px){nav #nav .nav-search #search-result{position:fixed;left:0;right:0;border-radius:0}}nav #nav .nav-search #search-result ul#searchResults{padding:0 0 0 20px}.page-note ol li,.page-note ul li,div.toc ol li,nav #nav .nav-search #search-result ul#searchResults li h3{margin-bottom:5px}nav #nav .nav-search #search-result ul#searchResults li h3 a{color:#efb232;white-space:inherit;padding:0;text-align:left;font-weight:400;font-size:16.5px;font-family:"Poppins",Arial,Helvetica,sans-serif;line-height:1.4}nav #nav .nav-search #search-result ul#searchResults li h3 a:hover{border-bottom:none;color:#8cc8ff}nav #nav .nav-search #search-result ul#searchResults li p{text-align:left;margin-top:0;line-height:1.4}nav #nav .nav-search #search-result #noResultsFound p{text-align:left}footer{font-size:1.1rem;background:#35373c;padding:.75rem 1rem;text-align:center;margin-top:3rem}footer a{color:#ccc}.danger,.info{position:relative;padding:16.5px;margin-bottom:24.75px;border:1px solid transparent;border-radius:.25rem;color:#eee;border-left-width:15px}.danger :last-child,.info :last-child{margin-bottom:0}.info{border-color:#8cc8ff}.danger{border-color:#f55}@media (min-width:768px){.col-2-equal{display:flex;align-items:stretch;flex-wrap:wrap}.col-2-equal>*{flex:0 0 50%;max-width:50%;overflow:auto}.col-2-equal>:nth-child(even){padding-left:5px}.col-2-equal>:nth-child(odd){padding-right:5px}.col-2-equal>*>code{height:100%}.col-2-equal+h2{margin-top:12.375px}}.hsbox{margin-bottom:24.75px;border:1px solid #969696;padding:1rem;border-radius:3px}.hsbox .hs__title{cursor:pointer}.hsbox .hs__title::before{content:" ";display:inline-block;border-top:7px solid transparent;border-bottom:7px solid transparent;border-left:7px solid currentColor;vertical-align:middle;margin-right:.7rem;transform:translateY(-2px);transition:transform .2s ease-out}.hsbox .hs__title.show{padding-bottom:15px;border-bottom:.5px solid #666;margin-bottom:1rem}.hsbox .hs__title.show+.hs__content{display:block;opacity:1;padding:5px 0;transition:all .25s 0s cubic-bezier(.4,0,.2,1)}.hsbox .hs__title.show::before{transform:rotate(90deg) translateX(-3px)}.hsbox .hs__content{display:none;transition:all .2s 0s ease}.hsbox .hs__content>:last-child{margin-bottom:0}blockquote{margin:0;margin-bottom:1.5rem;padding-left:1rem;border-left:5px solid #aaa}.page-note .text-center{text-align:center}.page-note ol,.page-note p,.page-note ul{margin-top:0;margin-bottom:24.75px}.page-note p+ol,.page-note p+ul{margin-top:-.5rem}.page-note ol li ol,.page-note ol li ul,.page-note ul li ol,.page-note ul li ul{margin-bottom:5px;padding-left:20px}.page-note ol li>*,.page-note ul li>*{margin-bottom:10px}.page-note p.noindent{display:none;padding-left:20px}.page-note p.noindent+ol,.page-note p.noindent+ul{padding-left:20px}.page-note p.indent{display:none;padding-left:40px}.page-note ol.indent,.page-note p.indent+ol,.page-note p.indent+ul,.page-note ul.indent{padding-left:40px}.page-note ol.noindent,.page-note ul.noindent{padding-left:20px}.page-note hr{border-bottom:1px solid #676767;margin-bottom:24.75px}#reading-list .item .author{font-style:italic}#reading-list .item .intro{color:#999}code[class*=language-],pre[class*=language-]{color:#eee;font-size:16px;text-shadow:none;font-family:Menlo,Monaco,Consolas,"Andale Mono","Ubuntu Mono","Courier New",monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#75a7ca}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}.token.comment{color:#6a9955}.token.punctuation{color:#eee}.token.inserted,.token.number{color:#b5cea8}.token.builtin,.token.string{color:#ce9178}.token.operator{color:#eee}.token.atrule{color:#ce9178}.token.atrule .token.url{color:#9cdcfe}.token.atrule .token.url .token.function{color:#efefac}.token.atrule .token.url .token.punctuation{color:#eee}.token.keyword{color:#90cdff}.token.function{color:#efefac}.token.constant{color:#9cdcfe}.token.class-name{color:#4ec9b0}.token.property,.token.variable{color:#9cdcfe}pre[class*=language-]>code[class*=language-]{position:relative;z-index:1}code,pre{font-family:Consolas,Menlo,Monaco,"Andale Mono WT","Andale Mono","Lucida Console","Lucida Sans Typewriter","DejaVu Sans Mono","Bitstream Vera Sans Mono","Liberation Mono","Nimbus Mono L","Courier New",Courier,monospace;line-height:1.5}h2>code{font-size:21.78px!important}:not(pre)>code{border:1px solid #444;background:#6b444245;padding:2px 4px;margin:0 1px;border-radius:3px;font-size:.9rem;color:#fff;word-break:break-word}h2>code{color:#ddd;padding-right:6px}a>code{color:#ffd479}a:hover>code{color:#ccc}pre,pre[class*=language-]{margin:0 0 27.225px;overflow:auto}pre>code,pre[class*=language-]>code{display:block;padding:14.5px 16.5px 16.5px;background:#2f3240;border:.5px solid #3b3e54;overflow:auto;border-radius:3px;max-height:450px}div.toc{margin-bottom:24.75px;border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:15px 15px 10px 0}div.toc>ol::before{content:"In this note";display:block;padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 15px;font-size:1.18rem;font-family:"Recoleta",Arial,Helvetica,sans-serif}div.toc ol{padding-left:20px;font-size:14.85px;margin-bottom:0}div.toc ol li code{font-size:.85rem;background:#ececec;padding:0 4px 2px}div.toc ol li ol{padding-left:10px;margin-top:7px}div.toc ol,div.toc ol ol{counter-reset:item;list-style-type:none}div.toc ol li::before{content:counters(item,".") ". ";counter-increment:item}div.toc>ol>li ol>li::before{opacity:.7}div.toc>ol>li::before{color:#8cc8ff}@media (min-width:1300px){div.toc{float:right;margin-right:-280px;border-left:none;width:250px;position:-webkit-sticky;position:sticky;top:60px;max-height:70vh;overflow:auto}div.toc ol{margin-top:0;margin-bottom:0}}@media (min-width:1500px){div.toc{margin-right:-310px;width:280px}}.toc-active>a{color:#fff!important}.toc-active::before{opacity:1!important}.page-note img{height:auto;width:100%}.page-note p>img+br{display:none}</style><header><nav><div id=nav><a href=/ class="nav-item no-effect"><img alt=home src=/img/nav/home.svg height=18 width=18> <span>Thi</span> </a><a href=/about/ class="nav-item no-effect"><img alt=about src=/img/nav/about.svg height=15 width=15> <span>About</span></a><div class=nav-search><form><input aria-label="search notes..." class=nav-search-input id=searchField placeholder="search notes..." type=search></form><div id=search-result style="display: none;"><ul id=searchResults></ul><div id=noResultsFound style="display: none;"><p>No results found.</div></div></div><a href=https://github.com/dinhanhthi class="nav-item no-effect nav-github" target=_blank><img alt=github src=/img/nav/github.svg height=20 width=20></a></div><div id=reading-progress aria-hidden=true></div></nav><div class=header-logo><img alt="Docker + GPUs" src=/img/header/docker.svg></div><h1>Docker + GPUs</h1><div id=more-info><div id=note-tag><a href=/tags/mlops>MLOps</a></div><div id=last-modified>01-12-2020 / <a href=https://github.com/dinhanhthi/dinhanhthi.com/edit/dev/./posts/deploy-run/2020-10-22-docker-gpu.md>Edit on Github</a></div></div></header><main><article><div class="container mt-2 normal page-note"><div class=toc><ol><li><a href=#wsl-%2B-windows>WSL + Windows</a><li><a href=#with-tensorflow-or-pytorch>With Tensorflow or PyTorch</a><li><a href=#basic-installation>Basic installation</a><li><a href=#check-info>Check info</a><li><a href=#install-nvidia-docker2>Install nvidia-docker2</a><li><a href=#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime>Difference: nvidia-container-toolkit vs nvidia-container-runtime</a><li><a href=#using-docker-compose%3F>Using docker-compose?</a><li><a href=#make-nvidia-work-in-docker-(linux)>Make NVIDIA work in docker (Linux)</a><li><a href=#references>References</a></ol></div><p>ðŸ‘‰ <a href=/docker>Docker note</a>.<h2 id=wsl-%2B-windows>WSL + Windows <a href=#wsl-%2B-windows class=direct-link>#</a></h2><p>Make WSL2 recognize GPU on Windows 10 ðŸ‘‰ Check <a href=https://docs.nvidia.com/cuda/wsl-user-guide/index.html>this tut</a>.<p>If you meet error "Your insider preview build settings need attention", restart many times don't solve the problem. ðŸ‘‰ Go to Account setting, then choose "Verify".<h2 id=with-tensorflow-or-pytorch>With Tensorflow or PyTorch <a href=#with-tensorflow-or-pytorch class=direct-link>#</a></h2><p>ðŸ‘‰ <a href=https://www.tensorflow.org/install/docker>Official doc for TF + docker</a><br>ðŸ‘‰ My <a href=/tensorflow#installation-with-docker>note for docker + TF</a>.<br>ðŸ‘‰ <a href=https://github.com/dinhanhthi/git_dataswati/tree/master/docker-thi>An example of docker pytorch with gpu support</a>.<h2 id=basic-installation>Basic installation <a href=#basic-installation class=direct-link>#</a></h2><p>It works perfectly on Pop!_OS 20.04,<pre class=language-bash><code class=language-bash><span class="token function">sudo</span> <span class="token function">apt</span> update<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-container-runtime<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-container-toolkit<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit<br><span class="token comment"># restard required</span></code></pre><h2 id=check-info>Check info <a href=#check-info class=direct-link>#</a></h2><pre class=language-bash><code class=language-bash><span class="token comment"># verify that your computer has a graphic card</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># First, install drivers and check</span><br>nvidia-smi<br><span class="token comment"># output: NVIDIA-SMI 450.80.02 Driver Version: 450.80.02    CUDA Version: 11.0</span><br><span class="token comment"># it's maximum CUDA version that your driver supports</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># check current version of cuda</span><br>nvcc --version<br><span class="token comment"># If there is not nvcc, it may be in /usr/local/cuda/bin/</span><br><span class="token comment"># Add this location to PATH</span><br><span class="token comment"># modify ~/.zshrc or ~/.bashrc</span><br><span class="token builtin class-name">export</span> <span class="token variable assign-left"><span class="token constant environment">PATH</span></span><span class="token operator">=</span>/usr/local/cuda/bin:<span class="token constant environment">$PATH</span><br><br><span class="token comment"># You may need to install</span><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># install and check nvidia-docker</span><br>dpkg -l <span class="token operator">|</span> <span class="token function">grep</span> nvidia-docker<br><span class="token comment"># or</span><br>nvidia-docker version</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Verifying â€“gpus option under docker run</span><br>docker run --help <span class="token operator">|</span> <span class="token function">grep</span> -i gpus<br><span class="token comment"># output: --gpus gpu-request GPU devices to add to the container ('all' to pass all GPUs)</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Listing out GPU devices</span><br>docker run -it --rm --gpus all ubuntu nvidia-smi -L<br><span class="token comment"># output: GPU 0: GeForce GTX 1650 (...)</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Verifying again with nvidia-smi</span><br>docker run -it --rm --gpus all ubuntu nvidia-smi</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># test a working setup container-toolkit</span><br>docker run --rm --gpus all nvidia/cuda nvidia-smi</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># test a working setup container-runtime</span><br>docker run --runtime<span class="token operator">=</span>nvidia --rm nvidia/cuda nvidia-smi<br><br><span class="token comment"># Error response from daemon: Unknown runtime specified nvidia.</span><br><span class="token comment"># Search below for "/etc/docker/daemon.json"</span><br><span class="token comment"># Maybe it helps.</span></code></pre><h2 id=install-nvidia-docker2>Install <code>nvidia-docker2</code> <a href=#install-nvidia-docker2 class=direct-link>#</a></h2><div class=hsbox><div class=hs__title>More information (<a href=https://github.com/NVIDIA/nvidia-docker/issues/1268>ref</a>)</div><div class=hs__content><blockquote><p>This package is the only docker-specific package of any of them. It takes the script associated with the <code>nvidia-container-runtime</code> and installs it into docker's <code>/etc/docker/daemon.json</code> file for you. This then allows you to run (for example) <code>docker run --runtime=nvidia ...</code> to automatically add GPU support to your containers. It also installs a wrapper script around the native docker CLI called <code>nvidia-docker</code> which lets you invoke docker without needing to specify <code>--runtime=nvidia</code> every single time. It also lets you set an environment variable on the host (NV_GPU) to specify which GPUs should be injected into a container.</blockquote></div></div><p>ðŸ‘‰ <a href=https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker>Officicial guide to install</a>.<pre class=language-bash><code class=language-bash><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/<span class="token variable">$distribution</span>/nvidia-docker.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-docker.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y nvidia-docker2<br><br><span class="token comment"># restart docker</span><br><span class="token function">sudo</span> systemctl restart docker</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># check version</span><br>nvidia-docker version</code></pre><h2 id=difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime>Difference: <code>nvidia-container-toolkit</code> vs <code>nvidia-container-runtime</code> <a href=#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime class=direct-link>#</a></h2><p>ðŸ‘‰ <a href=https://github.com/NVIDIA/nvidia-docker/issues/1268>What's the difference between the lastest nvidia-docker and nvidia container runtimeï¼Ÿ</a><blockquote><p>In this note, with Docker 19.03+ (<code>docker --version</code>), he says that <code>nvidia-container-toolkit</code> is used for <code>--gpus</code> (in <code>docker run ...</code>), <code>nvidia-container-runtime</code> is used for <code>--runtime=nvidia</code> (can also be used in <code>docker-compose</code> file).</blockquote><blockquote><p>However, <mark markdown=span>if you want to use Kubernetes with Docker 19.03, you actually <strong>need to continue using nvidia-docker2</strong></mark> because Kubernetes doesn't support passing GPU information down to docker through the <code>--gpus</code> flag yet. It still relies on the nvidia-container-runtime to pass GPU information down the stack via a set of environment variables.</blockquote><p>ðŸ‘‰ <a href=https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker>Installation Guide â€” NVIDIA Cloud Native Technologies documentation</a><h2 id=using-docker-compose%3F>Using docker-compose? <a href=#using-docker-compose%3F class=direct-link>#</a></h2><p>Purpose?<div class=col-2-equal><pre class=language-bash><code class=language-bash><span class="token comment"># instead of using</span><br>docker run <span class="token punctuation">\</span><br>    --gpus all<span class="token punctuation">\</span><br>    --name docker_thi_test<span class="token punctuation">\</span><br>    --rm<span class="token punctuation">\</span><br>    -v abc:abc<span class="token punctuation">\</span><br>    -p <span class="token number">8888</span>:8888</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># we use this with docker-compose.yml</span><br>docker-compose up</code></pre></div><pre class=language-bash><code class=language-bash><span class="token comment"># check version of docker-compose</span><br>docker-compose --version</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># If "version" in docker-compose.yml &lt; 2.3</span><br><span class="token comment"># Modify: /etc/docker/daemon.json</span><br><span class="token punctuation">{</span><br>    <span class="token string">"default-runtime"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia"</span>,<br>    <span class="token string">"runtimes"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>        <span class="token string">"nvidia"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>            <span class="token string">"path"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia-container-runtime"</span>,<br>            <span class="token string">"runtimeArgs"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># restart our docker daemon</span><br><span class="token function">sudo</span> <span class="token function">pkill</span> -SIGHUP dockerd</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># If "version" in docker-compose.yml >=2.3</span><br><span class="token comment"># docker-compose.yml => able to use "runtime"</span><br>version: <span class="token string">'2.3'</span> <span class="token comment"># MUST BE >=2.3 AND &lt;3</span><br>services:<br>  testing:<br>    ports:<br>      - <span class="token string">"8000:8000"</span><br>    runtime: nvidia<br>    volumes:<br>      - ./object_detection:/object_detection</code></pre><p>ðŸ‘‰ Check more in my repo <a href=https://github.com/dinhanhthi/my-dockerfiles>my-dockerfiles</a> on Github.<p>Run the test,<pre class=language-bash><code class=language-bash>docker pull tensorflow/tensorflow:latest-gpu-jupyter<br><span class="token function">mkdir</span> ~/Downloads/test/notebooks</code></pre><p>Without using <code>docker-compose.yml</code> (tensorflow) (cf. <a href=/tensorflow#without-docker-compose>this note</a> for more)<pre class=language-bash><code class=language-bash>docker run --name docker_thi_test -it --rm -v <span class="token variable"><span class="token variable">$(</span>realpath ~/Downloads/test/notebooks<span class="token variable">)</span></span>:/tf/notebooks -p <span class="token number">8888</span>:8888 tensorflow/tensorflow:latest-gpu-jupyter</code></pre><p>With <code>docker-compose.yml</code>?<pre class=language-bash><code class=language-bash><span class="token comment"># ~/Download/test/Dockerfile</span><br>FROM tensorflow/tensorflow:latest-gpu-jupyter</code></pre><pre class=language-yaml><code class=language-yaml><span class="token comment"># ~/Download/test/docker-compose.yml</span><br><span class="token atrule key">version</span><span class="token punctuation">:</span> <span class="token string">'2'</span><br><span class="token atrule key">services</span><span class="token punctuation">:</span><br>  <span class="token atrule key">jupyter</span><span class="token punctuation">:</span><br>    <span class="token atrule key">container_name</span><span class="token punctuation">:</span> <span class="token string">'docker_thi_test'</span><br>    <span class="token atrule key">build</span><span class="token punctuation">:</span> .<br>    <span class="token atrule key">volumes</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> ./notebooks<span class="token punctuation">:</span>/tf/notebooks <span class="token comment"># notebook directory</span><br>    <span class="token atrule key">ports</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> 8888<span class="token punctuation">:</span><span class="token number">8888</span> <span class="token comment"># exposed port for jupyter</span><br>    <span class="token atrule key">environment</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> NVIDIA_VISIBLE_DEVICES=0 <span class="token comment"># which gpu do you want to use for this container</span><br>        <span class="token punctuation">-</span> PASSWORD=12345</code></pre><p>Then run,<pre class=language-bash><code class=language-bash>docker-compose run --rm jupyter</code></pre><h2 id=make-nvidia-work-in-docker-(linux)>Make NVIDIA work in docker (Linux) <a href=#make-nvidia-work-in-docker-(linux) class=direct-link>#</a></h2><div class=danger><p>This section is still working (on 26-Oct-2020) but it's old for newer methods.</div><p><strong>Idea</strong>: Using NVIDIA driver of the base machine, don't install anything in docker!<div class=hsbox><div class=hs__title>Detail of steps</div><div class=hs__content><p class=noindent><ol><li><p>First, <a href=/pytorch#installation>maker sure</a> your base machine has an NVIDIA driver.<pre class=language-bash><code class=language-bash><span class="token comment"># list all gpus</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span><br><br><span class="token comment"># check nvidia & cuda versions</span><br>nvidia-smi</code></pre><li><p>Install <a href=https://github.com/NVIDIA/nvidia-container-runtime><code>nvidia-container-runtime</code></a><pre class=language-bash><code class=language-bash><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/<span class="token variable">$distribution</span>/nvidia-container-runtime.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-runtime.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-container-runtime</code></pre><li><p>Note that, <mark markdown=span>we cannot use <code>docker-compose.yml</code> in this case!!!</mark><li><p>Create an image <code>img_datas</code> with <code>Dockerfile</code> is<pre class=language-docker><code class=language-docker><span class="token keyword">FROM</span> nvidia/cuda<span class="token punctuation">:</span>10.2<span class="token punctuation">-</span>base<br><br><span class="token keyword">RUN</span> apt<span class="token punctuation">-</span>get update && \<br>	apt<span class="token punctuation">-</span>get <span class="token punctuation">-</span>y upgrade && \<br>	apt<span class="token punctuation">-</span>get install <span class="token punctuation">-</span>y python3<span class="token punctuation">-</span>pip python3<span class="token punctuation">-</span>dev locales git<br><br><span class="token comment"># install dependencies</span><br><span class="token keyword">COPY</span> requirements.txt requirements.txt<br><span class="token keyword">RUN</span> python3 <span class="token punctuation">-</span>m pip install <span class="token punctuation">-</span><span class="token punctuation">-</span>upgrade pip && \<br>	python3 <span class="token punctuation">-</span>m pip install <span class="token punctuation">-</span>r requirements.txt<br><span class="token keyword">COPY</span> . .<br><br><span class="token comment"># default command</span><br><span class="token keyword">CMD</span> <span class="token punctuation">[</span> <span class="token string">"jupyter"</span><span class="token punctuation">,</span> <span class="token string">"lab"</span><span class="token punctuation">,</span> <span class="token string">"--no-browser"</span><span class="token punctuation">,</span> <span class="token string">"--allow-root"</span><span class="token punctuation">,</span> <span class="token string">"--ip=0.0.0.0"</span>  <span class="token punctuation">]</span></code></pre><li><p>Create a container,<pre class=language-bash><code class=language-bash>docker run --name docker_thi --gpus all -v /home/thi/folder_1/:/srv/folder_1/ -v /home/thi/folder_1/git/:/srv/folder_2 -dp <span class="token number">8888</span>:8888 -w<span class="token operator">=</span><span class="token string">"/srv"</span> -it img_datas<br><br><span class="token comment"># -v: volumes</span><br><span class="token comment"># -w: working dir</span><br><span class="token comment"># --gpus all: using all gpus on base machine</span></code></pre></ol><p><a href=https://towardsdatascience.com/how-to-properly-use-the-gpu-within-a-docker-container-4c699c78c6d1>This article</a> is also very interesting and helpful in some cases.</div></div><h2 id=references>References <a href=#references class=direct-link>#</a></h2><ol><li><a href=https://github.com/NVIDIA/nvidia-docker/wiki/CUDA>Difference between <code>base</code>, <code>runtime</code> and <code>devel</code> in <code>Dockerfile</code> of CUDA</a>.<li><a href=https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles>Dockerfile on Github</a> of Tensorflow.</ol></div><script type=application/ld+json>{
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "Docker + GPUs",
        "image": [],
        "author": "Anh-Thi DINH",
        "genre": "Insert a schema.org genre",
        "url": "https://dinhanhthi.com/docker-gpu/",
        "mainEntityOfPage": "https://dinhanhthi.com/docker-gpu/",
        "datePublished": "21-10-2020",
        "dateModified": "01-12-2020",
        "description": "ðŸ‘‰ Docker note. WSL + Windows # Make WSL2 recognize GPU on Windows 10 ðŸ‘‰ Check this tut. If you meet error &amp;quot;Your insider preview build..."
      }</script></article></main><footer><a href=/ target=_blank>Thi Â Â©Â  2020 </a>Â â€¢Â  <a href=/about-the-notes/ >About the notes </a>Â â€¢Â  <a href=https://pobo.dinhanhthi.com target=_blank>Po Bo </a>Â â€¢Â  <a href=/for-me-only/ >For me only </a>Â â€¢Â  <a href=/donate/ >Support Thi</a></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js></script>